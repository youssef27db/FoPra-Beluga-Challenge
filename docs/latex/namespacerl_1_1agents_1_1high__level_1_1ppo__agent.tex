\doxysection{rl.\+agents.\+high\+\_\+level.\+ppo\+\_\+agent Namespace Reference}
\hypertarget{namespacerl_1_1agents_1_1high__level_1_1ppo__agent}{}\label{namespacerl_1_1agents_1_1high__level_1_1ppo__agent}\index{rl.agents.high\_level.ppo\_agent@{rl.agents.high\_level.ppo\_agent}}
\doxysubsubsection*{Classes}
\begin{DoxyCompactItemize}
\item 
class \mbox{\hyperlink{classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_actor_network}{Actor\+Network}}
\begin{DoxyCompactList}\small\item\em Actor network for PPO agent. \end{DoxyCompactList}\item 
class \mbox{\hyperlink{classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_critic_network}{Critic\+Network}}
\begin{DoxyCompactList}\small\item\em Critic network for PPO agent. \end{DoxyCompactList}\item 
class \mbox{\hyperlink{classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent}{PPOAgent}}
\begin{DoxyCompactList}\small\item\em Proximal Policy Optimization (PPO) agent implementation. \end{DoxyCompactList}\item 
class \mbox{\hyperlink{classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_memory}{PPOMemory}}
\begin{DoxyCompactList}\small\item\em Memory buffer for storing PPO training experiences. \end{DoxyCompactList}\end{DoxyCompactItemize}
