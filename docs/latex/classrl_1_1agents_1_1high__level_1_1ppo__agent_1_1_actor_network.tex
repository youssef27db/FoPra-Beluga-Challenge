\doxysection{rl.\+agents.\+high\+\_\+level.\+ppo\+\_\+agent.\+Actor\+Network Class Reference}
\hypertarget{classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_actor_network}{}\label{classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_actor_network}\index{rl.agents.high\_level.ppo\_agent.ActorNetwork@{rl.agents.high\_level.ppo\_agent.ActorNetwork}}


Actor network for PPO agent.  




Inherits nn.\+Module.

\doxysubsubsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
\mbox{\hyperlink{classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_actor_network_aee7d89c100fcc1aee1870322de45a72d}{\+\_\+\+\_\+init\+\_\+\+\_\+}} (self, n\+\_\+actions, input\+\_\+dims, alpha, fc1dims=256, fc2dims=256, fc3dims=128, chkpt\+\_\+dir=\textquotesingle{}tmp/ppo\textquotesingle{}, name=\textquotesingle{}ppo\textquotesingle{})
\begin{DoxyCompactList}\small\item\em Initialize the actor network. \end{DoxyCompactList}\item 
\mbox{\hyperlink{classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_actor_network_a205adbf70f3a9fa366ab0fcdee380333}{forward}} (self, state)
\begin{DoxyCompactList}\small\item\em Forward pass through the actor network. \end{DoxyCompactList}\item 
\mbox{\hyperlink{classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_actor_network_a8bc09dc4a05f9d935d74e45d2d7e459c}{save\+\_\+checkpoint}} (self)
\begin{DoxyCompactList}\small\item\em Save the current model state to checkpoint file. \end{DoxyCompactList}\item 
\mbox{\hyperlink{classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_actor_network_a0f4ea4666192124613d9c1073cd5951c}{load\+\_\+checkpoint}} (self)
\begin{DoxyCompactList}\small\item\em Load model state from checkpoint file. \end{DoxyCompactList}\end{DoxyCompactItemize}
\doxysubsubsection*{Public Attributes}
\begin{DoxyCompactItemize}
\item 
\mbox{\hyperlink{classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_actor_network_a67e4554ca3dd016844a0073df5ff6cbf}{checkpoint\+\_\+file}} = os.\+path.\+join(chkpt\+\_\+dir, \textquotesingle{}actor\+\_\+torch\+\_\+\textquotesingle{} + name)
\item 
\mbox{\hyperlink{classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_actor_network_a28ce44f0321d73d4cbcef057607fcf16}{actor}}
\item 
\mbox{\hyperlink{classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_actor_network_a94510c3daa25640bed11a76900a888a5}{optimizer}} = optim.\+Adam(self.\+parameters(), lr=alpha)
\item 
\mbox{\hyperlink{classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_actor_network_a1a3c826967f0c48bd422494b0a61aa35}{device}} = T.\+device(\textquotesingle{}cuda\textquotesingle{} if T.\+cuda.\+is\+\_\+available() else \textquotesingle{}cpu\textquotesingle{})
\end{DoxyCompactItemize}


\doxysubsection{Detailed Description}
Actor network for PPO agent. 

Neural network that outputs action probabilities given a state. Uses a categorical distribution for discrete action spaces. 

\doxysubsection{Constructor \& Destructor Documentation}
\Hypertarget{classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_actor_network_aee7d89c100fcc1aee1870322de45a72d}\index{rl.agents.high\_level.ppo\_agent.ActorNetwork@{rl.agents.high\_level.ppo\_agent.ActorNetwork}!\_\_init\_\_@{\_\_init\_\_}}
\index{\_\_init\_\_@{\_\_init\_\_}!rl.agents.high\_level.ppo\_agent.ActorNetwork@{rl.agents.high\_level.ppo\_agent.ActorNetwork}}
\doxysubsubsection{\texorpdfstring{\_\_init\_\_()}{\_\_init\_\_()}}
{\footnotesize\ttfamily \label{classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_actor_network_aee7d89c100fcc1aee1870322de45a72d} 
rl.\+agents.\+high\+\_\+level.\+ppo\+\_\+agent.\+Actor\+Network.\+\_\+\+\_\+init\+\_\+\+\_\+ (\begin{DoxyParamCaption}\item[{}]{self}{, }\item[{}]{n\+\_\+actions}{, }\item[{}]{input\+\_\+dims}{, }\item[{}]{alpha}{, }\item[{}]{fc1dims}{ = {\ttfamily 256}, }\item[{}]{fc2dims}{ = {\ttfamily 256}, }\item[{}]{fc3dims}{ = {\ttfamily 128}, }\item[{}]{chkpt\+\_\+dir}{ = {\ttfamily \textquotesingle{}tmp/ppo\textquotesingle{}}, }\item[{}]{name}{ = {\ttfamily \textquotesingle{}ppo\textquotesingle{}}}\end{DoxyParamCaption})}



Initialize the actor network. 


\begin{DoxyParams}{Parameters}
{\em n\+\_\+actions} & Number of possible actions \\
\hline
{\em input\+\_\+dims} & Dimension of input state space \\
\hline
{\em alpha} & Learning rate for optimization \\
\hline
{\em fc1dims} & Number of neurons in first hidden layer \\
\hline
{\em fc2dims} & Number of neurons in second hidden layer ~\newline
 \\
\hline
{\em fc3dims} & Number of neurons in third hidden layer \\
\hline
{\em chkpt\+\_\+dir} & Directory for saving checkpoints \\
\hline
{\em name} & Model name for checkpoint files \\
\hline
\end{DoxyParams}

\begin{DoxyCode}{0}
\DoxyCodeLine{00083\ \ \ \ \ \textcolor{keyword}{def\ }\_\_init\_\_(self,\ n\_actions,\ input\_dims,\ alpha,\ fc1dims=256,\ fc2dims=256,\ fc3dims=128,\ chkpt\_dir='tmp/ppo',\ name\ =\ 'ppo'): }
\DoxyCodeLine{00084\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}"{}"{}! }}
\DoxyCodeLine{00085\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ @brief\ Initialize\ the\ actor\ network }}
\DoxyCodeLine{00086\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ @param\ n\_actions\ Number\ of\ possible\ actions }}
\DoxyCodeLine{00087\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ @param\ input\_dims\ Dimension\ of\ input\ state\ space }}
\DoxyCodeLine{00088\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ @param\ alpha\ Learning\ rate\ for\ optimization }}
\DoxyCodeLine{00089\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ @param\ fc1dims\ Number\ of\ neurons\ in\ first\ hidden\ layer }}
\DoxyCodeLine{00090\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ @param\ fc2dims\ Number\ of\ neurons\ in\ second\ hidden\ layer\ \  }}
\DoxyCodeLine{00091\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ @param\ fc3dims\ Number\ of\ neurons\ in\ third\ hidden\ layer }}
\DoxyCodeLine{00092\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ @param\ chkpt\_dir\ Directory\ for\ saving\ checkpoints }}
\DoxyCodeLine{00093\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ @param\ name\ Model\ name\ for\ checkpoint\ files }}
\DoxyCodeLine{00094\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ "{}"{}"{}} }
\DoxyCodeLine{00095\ \ \ \ \ \ \ \ \ super(ActorNetwork,\ self).\_\_init\_\_() }
\DoxyCodeLine{00096\  }
\DoxyCodeLine{00097\ \ \ \ \ \ \ \ \ self.checkpoint\_file\ =\ os.path.join(chkpt\_dir,\ \textcolor{stringliteral}{'actor\_torch\_'}\ +\ name) }
\DoxyCodeLine{00098\ \ \ \ \ \ \ \ \ self.actor\ =\ nn.Sequential(nn.Linear(input\_dims,\ fc1dims),\ nn.ReLU(), }
\DoxyCodeLine{00099\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ nn.Linear(fc1dims,\ fc2dims),\ nn.ReLU(), }
\DoxyCodeLine{00100\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ nn.Linear(fc2dims,\ fc3dims),\ nn.ReLU(), }
\DoxyCodeLine{00101\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ nn.Linear(fc3dims,\ n\_actions),\ nn.Softmax(dim=-\/1)) }
\DoxyCodeLine{00102\  }
\DoxyCodeLine{00103\ \ \ \ \ \ \ \ \ self.optimizer\ =\ optim.Adam(self.parameters(),\ lr=alpha) }
\DoxyCodeLine{00104\ \ \ \ \ \ \ \ \ self.device\ =\ T.device(\textcolor{stringliteral}{'cuda'}\ \textcolor{keywordflow}{if}\ T.cuda.is\_available()\ \textcolor{keywordflow}{else}\ \textcolor{stringliteral}{'cpu'}) }
\DoxyCodeLine{00105\ \ \ \ \ \ \ \ \ self.to(self.device) }
\DoxyCodeLine{00106\  }

\end{DoxyCode}


\doxysubsection{Member Function Documentation}
\Hypertarget{classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_actor_network_a205adbf70f3a9fa366ab0fcdee380333}\index{rl.agents.high\_level.ppo\_agent.ActorNetwork@{rl.agents.high\_level.ppo\_agent.ActorNetwork}!forward@{forward}}
\index{forward@{forward}!rl.agents.high\_level.ppo\_agent.ActorNetwork@{rl.agents.high\_level.ppo\_agent.ActorNetwork}}
\doxysubsubsection{\texorpdfstring{forward()}{forward()}}
{\footnotesize\ttfamily \label{classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_actor_network_a205adbf70f3a9fa366ab0fcdee380333} 
rl.\+agents.\+high\+\_\+level.\+ppo\+\_\+agent.\+Actor\+Network.\+forward (\begin{DoxyParamCaption}\item[{}]{self}{, }\item[{}]{state}{}\end{DoxyParamCaption})}



Forward pass through the actor network. 


\begin{DoxyParams}{Parameters}
{\em state} & Input state tensor \\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
Categorical distribution over actions 
\end{DoxyReturn}

\begin{DoxyCode}{0}
\DoxyCodeLine{00107\ \ \ \ \ \textcolor{keyword}{def\ }forward(self,\ state): }
\DoxyCodeLine{00108\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}"{}"{}! }}
\DoxyCodeLine{00109\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ @brief\ Forward\ pass\ through\ the\ actor\ network }}
\DoxyCodeLine{00110\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ @param\ state\ Input\ state\ tensor }}
\DoxyCodeLine{00111\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ @return\ Categorical\ distribution\ over\ actions }}
\DoxyCodeLine{00112\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ "{}"{}"{}} }
\DoxyCodeLine{00113\ \ \ \ \ \ \ \ \ dist\ =\ self.actor(state) }
\DoxyCodeLine{00114\ \ \ \ \ \ \ \ \ dist\ =\ Categorical(dist) }
\DoxyCodeLine{00115\  }
\DoxyCodeLine{00116\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{return}\ dist }
\DoxyCodeLine{00117\  }

\end{DoxyCode}
\Hypertarget{classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_actor_network_a0f4ea4666192124613d9c1073cd5951c}\index{rl.agents.high\_level.ppo\_agent.ActorNetwork@{rl.agents.high\_level.ppo\_agent.ActorNetwork}!load\_checkpoint@{load\_checkpoint}}
\index{load\_checkpoint@{load\_checkpoint}!rl.agents.high\_level.ppo\_agent.ActorNetwork@{rl.agents.high\_level.ppo\_agent.ActorNetwork}}
\doxysubsubsection{\texorpdfstring{load\_checkpoint()}{load\_checkpoint()}}
{\footnotesize\ttfamily \label{classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_actor_network_a0f4ea4666192124613d9c1073cd5951c} 
rl.\+agents.\+high\+\_\+level.\+ppo\+\_\+agent.\+Actor\+Network.\+load\+\_\+checkpoint (\begin{DoxyParamCaption}\item[{}]{self}{}\end{DoxyParamCaption})}



Load model state from checkpoint file. 


\begin{DoxyCode}{0}
\DoxyCodeLine{00124\ \ \ \ \ \textcolor{keyword}{def\ }load\_checkpoint(self): }
\DoxyCodeLine{00125\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}"{}"{}! }}
\DoxyCodeLine{00126\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ @brief\ Load\ model\ state\ from\ checkpoint\ file }}
\DoxyCodeLine{00127\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ "{}"{}"{}} }
\DoxyCodeLine{00128\ \ \ \ \ \ \ \ \ self.load\_state\_dict(T.load(self.checkpoint\_file)) }
\DoxyCodeLine{00129\  }
\DoxyCodeLine{00130\  }

\end{DoxyCode}
\Hypertarget{classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_actor_network_a8bc09dc4a05f9d935d74e45d2d7e459c}\index{rl.agents.high\_level.ppo\_agent.ActorNetwork@{rl.agents.high\_level.ppo\_agent.ActorNetwork}!save\_checkpoint@{save\_checkpoint}}
\index{save\_checkpoint@{save\_checkpoint}!rl.agents.high\_level.ppo\_agent.ActorNetwork@{rl.agents.high\_level.ppo\_agent.ActorNetwork}}
\doxysubsubsection{\texorpdfstring{save\_checkpoint()}{save\_checkpoint()}}
{\footnotesize\ttfamily \label{classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_actor_network_a8bc09dc4a05f9d935d74e45d2d7e459c} 
rl.\+agents.\+high\+\_\+level.\+ppo\+\_\+agent.\+Actor\+Network.\+save\+\_\+checkpoint (\begin{DoxyParamCaption}\item[{}]{self}{}\end{DoxyParamCaption})}



Save the current model state to checkpoint file. 


\begin{DoxyCode}{0}
\DoxyCodeLine{00118\ \ \ \ \ \textcolor{keyword}{def\ }save\_checkpoint(self): }
\DoxyCodeLine{00119\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}"{}"{}! }}
\DoxyCodeLine{00120\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ @brief\ Save\ the\ current\ model\ state\ to\ checkpoint\ file }}
\DoxyCodeLine{00121\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ "{}"{}"{}} }
\DoxyCodeLine{00122\ \ \ \ \ \ \ \ \ T.save(self.state\_dict(),\ self.checkpoint\_file) }
\DoxyCodeLine{00123\  }

\end{DoxyCode}


\doxysubsection{Member Data Documentation}
\Hypertarget{classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_actor_network_a28ce44f0321d73d4cbcef057607fcf16}\index{rl.agents.high\_level.ppo\_agent.ActorNetwork@{rl.agents.high\_level.ppo\_agent.ActorNetwork}!actor@{actor}}
\index{actor@{actor}!rl.agents.high\_level.ppo\_agent.ActorNetwork@{rl.agents.high\_level.ppo\_agent.ActorNetwork}}
\doxysubsubsection{\texorpdfstring{actor}{actor}}
{\footnotesize\ttfamily \label{classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_actor_network_a28ce44f0321d73d4cbcef057607fcf16} 
rl.\+agents.\+high\+\_\+level.\+ppo\+\_\+agent.\+Actor\+Network.\+actor}

{\bfseries Initial value\+:}
\begin{DoxyCode}{0}
\DoxyCodeLine{=\ \ nn.Sequential(nn.Linear(input\_dims,\ fc1dims),\ nn.ReLU(),}
\DoxyCodeLine{\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ nn.Linear(fc1dims,\ fc2dims),\ nn.ReLU(),}
\DoxyCodeLine{\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ nn.Linear(fc2dims,\ fc3dims),\ nn.ReLU(),}
\DoxyCodeLine{\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ nn.Linear(fc3dims,\ n\_actions),\ nn.Softmax(dim=-\/1))}

\end{DoxyCode}
\Hypertarget{classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_actor_network_a67e4554ca3dd016844a0073df5ff6cbf}\index{rl.agents.high\_level.ppo\_agent.ActorNetwork@{rl.agents.high\_level.ppo\_agent.ActorNetwork}!checkpoint\_file@{checkpoint\_file}}
\index{checkpoint\_file@{checkpoint\_file}!rl.agents.high\_level.ppo\_agent.ActorNetwork@{rl.agents.high\_level.ppo\_agent.ActorNetwork}}
\doxysubsubsection{\texorpdfstring{checkpoint\_file}{checkpoint\_file}}
{\footnotesize\ttfamily \label{classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_actor_network_a67e4554ca3dd016844a0073df5ff6cbf} 
rl.\+agents.\+high\+\_\+level.\+ppo\+\_\+agent.\+Actor\+Network.\+checkpoint\+\_\+file = os.\+path.\+join(chkpt\+\_\+dir, \textquotesingle{}actor\+\_\+torch\+\_\+\textquotesingle{} + name)}

\Hypertarget{classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_actor_network_a1a3c826967f0c48bd422494b0a61aa35}\index{rl.agents.high\_level.ppo\_agent.ActorNetwork@{rl.agents.high\_level.ppo\_agent.ActorNetwork}!device@{device}}
\index{device@{device}!rl.agents.high\_level.ppo\_agent.ActorNetwork@{rl.agents.high\_level.ppo\_agent.ActorNetwork}}
\doxysubsubsection{\texorpdfstring{device}{device}}
{\footnotesize\ttfamily \label{classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_actor_network_a1a3c826967f0c48bd422494b0a61aa35} 
rl.\+agents.\+high\+\_\+level.\+ppo\+\_\+agent.\+Actor\+Network.\+device = T.\+device(\textquotesingle{}cuda\textquotesingle{} if T.\+cuda.\+is\+\_\+available() else \textquotesingle{}cpu\textquotesingle{})}

\Hypertarget{classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_actor_network_a94510c3daa25640bed11a76900a888a5}\index{rl.agents.high\_level.ppo\_agent.ActorNetwork@{rl.agents.high\_level.ppo\_agent.ActorNetwork}!optimizer@{optimizer}}
\index{optimizer@{optimizer}!rl.agents.high\_level.ppo\_agent.ActorNetwork@{rl.agents.high\_level.ppo\_agent.ActorNetwork}}
\doxysubsubsection{\texorpdfstring{optimizer}{optimizer}}
{\footnotesize\ttfamily \label{classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_actor_network_a94510c3daa25640bed11a76900a888a5} 
rl.\+agents.\+high\+\_\+level.\+ppo\+\_\+agent.\+Actor\+Network.\+optimizer = optim.\+Adam(self.\+parameters(), lr=alpha)}



The documentation for this class was generated from the following file\+:\begin{DoxyCompactItemize}
\item 
rl/agents/high\+\_\+level/ppo\+\_\+agent.\+py\end{DoxyCompactItemize}
