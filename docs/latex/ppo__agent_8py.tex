\doxysection{rl/agents/high\+\_\+level/ppo\+\_\+agent.py File Reference}
\hypertarget{ppo__agent_8py}{}\label{ppo__agent_8py}\index{rl/agents/high\_level/ppo\_agent.py@{rl/agents/high\_level/ppo\_agent.py}}
\doxysubsubsection*{Classes}
\begin{DoxyCompactItemize}
\item 
class \mbox{\hyperlink{classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_memory}{rl.\+agents.\+high\+\_\+level.\+ppo\+\_\+agent.\+PPOMemory}}
\begin{DoxyCompactList}\small\item\em Memory buffer for storing PPO training experiences. \end{DoxyCompactList}\item 
class \mbox{\hyperlink{classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_actor_network}{rl.\+agents.\+high\+\_\+level.\+ppo\+\_\+agent.\+Actor\+Network}}
\begin{DoxyCompactList}\small\item\em Actor network for PPO agent. \end{DoxyCompactList}\item 
class \mbox{\hyperlink{classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_critic_network}{rl.\+agents.\+high\+\_\+level.\+ppo\+\_\+agent.\+Critic\+Network}}
\begin{DoxyCompactList}\small\item\em Critic network for PPO agent. \end{DoxyCompactList}\item 
class \mbox{\hyperlink{classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent}{rl.\+agents.\+high\+\_\+level.\+ppo\+\_\+agent.\+PPOAgent}}
\begin{DoxyCompactList}\small\item\em Proximal Policy Optimization (PPO) agent implementation. \end{DoxyCompactList}\end{DoxyCompactItemize}
\doxysubsubsection*{Namespaces}
\begin{DoxyCompactItemize}
\item 
namespace \mbox{\hyperlink{namespacerl}{rl}}
\item 
namespace \mbox{\hyperlink{namespacerl_1_1agents}{rl.\+agents}}
\item 
namespace \mbox{\hyperlink{namespacerl_1_1agents_1_1high__level}{rl.\+agents.\+high\+\_\+level}}
\item 
namespace \mbox{\hyperlink{namespacerl_1_1agents_1_1high__level_1_1ppo__agent}{rl.\+agents.\+high\+\_\+level.\+ppo\+\_\+agent}}
\end{DoxyCompactItemize}
