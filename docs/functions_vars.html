<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.12.0"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>FoPra Beluga Challenge - Reinforcement Learning: Class Members - Variables</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<script type="text/javascript" src="clipboard.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="cookie.js"></script>
<script type="text/javascript" src="darkmode_toggle.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">FoPra Beluga Challenge - Reinforcement Learning<span id="projectnumber">&#160;v1.0</span>
   </div>
   <div id="projectbrief">Deep Reinforcement Learning solution for the Beluga Challenge shipping container optimization problem using PPO and MCTS</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.12.0 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() { codefold.init(0); });
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',false,false,'search.php','Search',true);
});
/* @license-end */
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function(){initNavTree('functions_vars.html',''); initResizable(true); });
/* @license-end */
</script>
<div id="doc-content">
<div class="contents">
<div class="textblock">Here is a list of all variables with links to the classes they belong to:</div>

<h3><a id="index_a" name="index_a"></a>- a -</h3><ul>
<li>action&#160;:&#160;<a class="el" href="classrl_1_1mcts_1_1mcts__node_1_1_m_c_t_s_node.html#ae2593b09a9d8644897706df1b60509cc">rl.mcts.mcts_node.MCTSNode</a></li>
<li>action_mapping&#160;:&#160;<a class="el" href="classrl_1_1training_1_1trainer_1_1_trainer.html#adb48f26c55ad6a951e8d18e9d5a0a123">rl.training.trainer.Trainer</a></li>
<li>actions&#160;:&#160;<a class="el" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_memory.html#a3bf4561f4eb99d3693f9128ae0522b69">rl.agents.high_level.ppo_agent.PPOMemory</a></li>
<li>actor&#160;:&#160;<a class="el" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_actor_network.html#a28ce44f0321d73d4cbcef057607fcf16">rl.agents.high_level.ppo_agent.ActorNetwork</a>, <a class="el" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent.html#a30d5505efa99710341c579de4f3c7c03">rl.agents.high_level.ppo_agent.PPOAgent</a></li>
<li>avg_rewards&#160;:&#160;<a class="el" href="classrl_1_1training_1_1trainer_1_1_trainer.html#a1ec86533932a55f2d8aa0f088b11dad8">rl.training.trainer.Trainer</a></li>
</ul>


<h3><a id="index_b" name="index_b"></a>- b -</h3><ul>
<li>base_index&#160;:&#160;<a class="el" href="classrl_1_1env_1_1environment_1_1_env.html#a041938f61fdf28ed2ee7b005f69bff35">rl.env.environment.Env</a></li>
<li>batch_size&#160;:&#160;<a class="el" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_memory.html#a0c97a17d1a3dd1bcfbe8bc82655dee63">rl.agents.high_level.ppo_agent.PPOMemory</a></li>
<li>belugas&#160;:&#160;<a class="el" href="classrl_1_1env_1_1state_1_1_problem_state.html#af7a668fd5d7311137fe84d611a92de66">rl.env.state.ProblemState</a></li>
<li>belugas_finished&#160;:&#160;<a class="el" href="classrl_1_1env_1_1state_1_1_problem_state.html#af088447f7a3f7640f6c50734be85f617">rl.env.state.ProblemState</a></li>
<li>belugas_unloaded&#160;:&#160;<a class="el" href="classrl_1_1env_1_1state_1_1_problem_state.html#a2c2ebd2dee9819c34dc89d9a07176b40">rl.env.state.ProblemState</a></li>
<li>best_score&#160;:&#160;<a class="el" href="classrl_1_1training_1_1trainer_1_1_trainer.html#af53b12fdc00175204aa94499c5001b81">rl.training.trainer.Trainer</a></li>
<li>block_size&#160;:&#160;<a class="el" href="classrl_1_1env_1_1environment_1_1_env.html#aa7aeae08ab212e94a1daf3d11e516c1a">rl.env.environment.Env</a></li>
</ul>


<h3><a id="index_c" name="index_c"></a>- c -</h3><ul>
<li>check_action_map&#160;:&#160;<a class="el" href="classrl_1_1env_1_1environment_1_1_env.html#a30f8172ea1dc5ad2e16a7f72015ba466">rl.env.environment.Env</a></li>
<li>checkpoint_file&#160;:&#160;<a class="el" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_actor_network.html#a67e4554ca3dd016844a0073df5ff6cbf">rl.agents.high_level.ppo_agent.ActorNetwork</a>, <a class="el" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_critic_network.html#a0f8199be7d8c7e801ff0b88336b96213">rl.agents.high_level.ppo_agent.CriticNetwork</a></li>
<li>children&#160;:&#160;<a class="el" href="classrl_1_1mcts_1_1mcts__node_1_1_m_c_t_s_node.html#ac78169388028a21c56a5ff598fc7b5b9">rl.mcts.mcts_node.MCTSNode</a></li>
<li>critic&#160;:&#160;<a class="el" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_critic_network.html#a824b1eed500fc53536c0f7e01d176988">rl.agents.high_level.ppo_agent.CriticNetwork</a>, <a class="el" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent.html#a476d79433aee6877dcf08d4985a8b798">rl.agents.high_level.ppo_agent.PPOAgent</a></li>
<li>current_jigs&#160;:&#160;<a class="el" href="classrl_1_1env_1_1state_1_1_beluga.html#affbcc110536b510976bceb58d53ead5a">rl.env.state.Beluga</a>, <a class="el" href="classrl_1_1env_1_1state_1_1_rack.html#a6ae6d2976b7d1c284a414e61ae314047">rl.env.state.Rack</a></li>
</ul>


<h3><a id="index_d" name="index_d"></a>- d -</h3><ul>
<li>debug&#160;:&#160;<a class="el" href="classrl_1_1mcts_1_1mcts_1_1_m_c_t_s.html#adbbff374479f0397a831fbbd3059dec8">rl.mcts.mcts.MCTS</a>, <a class="el" href="classrl_1_1training_1_1trainer_1_1_trainer.html#a458358bedca5762d1d0413497d29c8e5">rl.training.trainer.Trainer</a></li>
<li>depth&#160;:&#160;<a class="el" href="classrl_1_1mcts_1_1mcts_1_1_m_c_t_s.html#aab310caec54328f75daa9e0a82fa35c7">rl.mcts.mcts.MCTS</a>, <a class="el" href="classrl_1_1mcts_1_1mcts__node_1_1_m_c_t_s_node.html#a18c2a407fd2344930e0fe8a0b750f1aa">rl.mcts.mcts_node.MCTSNode</a></li>
<li>device&#160;:&#160;<a class="el" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_actor_network.html#a1a3c826967f0c48bd422494b0a61aa35">rl.agents.high_level.ppo_agent.ActorNetwork</a>, <a class="el" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_critic_network.html#a83eec626281fcdfb93996bb50aee40a8">rl.agents.high_level.ppo_agent.CriticNetwork</a></li>
<li>dones&#160;:&#160;<a class="el" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_memory.html#a0e9efad74c28d7fd7e7bd0fda0257cac">rl.agents.high_level.ppo_agent.PPOMemory</a></li>
</ul>


<h3><a id="index_e" name="index_e"></a>- e -</h3><ul>
<li>empty&#160;:&#160;<a class="el" href="classrl_1_1env_1_1state_1_1_jig.html#a68885bbdf9c75afa2c5be415f3d090f2">rl.env.state.Jig</a></li>
<li>env&#160;:&#160;<a class="el" href="classrl_1_1training_1_1trainer_1_1_trainer.html#a7eca82735158f766fee6550d4086ddc6">rl.training.trainer.Trainer</a></li>
<li>episode_rewards&#160;:&#160;<a class="el" href="classrl_1_1training_1_1trainer_1_1_trainer.html#aaebca8d0c1d7f5e7c02bb68a4a5105c0">rl.training.trainer.Trainer</a></li>
<li>epsilon_decay&#160;:&#160;<a class="el" href="classrl_1_1training_1_1trainer_1_1_trainer.html#ae8cb00e5c5eeb0624259f76b10dd8b3a">rl.training.trainer.Trainer</a></li>
<li>epsilon_end&#160;:&#160;<a class="el" href="classrl_1_1training_1_1trainer_1_1_trainer.html#a83ce46e90e7197ace0a2448eedabb0ef">rl.training.trainer.Trainer</a></li>
<li>epsilon_start&#160;:&#160;<a class="el" href="classrl_1_1training_1_1trainer_1_1_trainer.html#a2f807ad2ea6c9325d2e51553bfbe7275">rl.training.trainer.Trainer</a></li>
</ul>


<h3><a id="index_g" name="index_g"></a>- g -</h3><ul>
<li>gae_lambda&#160;:&#160;<a class="el" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent.html#a2e14dfc5da07b12391625092aad3a8da">rl.agents.high_level.ppo_agent.PPOAgent</a></li>
<li>gamma&#160;:&#160;<a class="el" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent.html#a9a01dc3182b551836c5549a8c172b651">rl.agents.high_level.ppo_agent.PPOAgent</a></li>
</ul>


<h3><a id="index_h" name="index_h"></a>- h -</h3><ul>
<li>hangars&#160;:&#160;<a class="el" href="classrl_1_1env_1_1state_1_1_problem_state.html#a30bbf7cf17dd79bf56b6fd36c0db3730">rl.env.state.ProblemState</a></li>
</ul>


<h3><a id="index_i" name="index_i"></a>- i -</h3><ul>
<li>invalid_action_counts&#160;:&#160;<a class="el" href="classrl_1_1training_1_1trainer_1_1_trainer.html#abaf51c0b6caf143683b15263adf6f76c">rl.training.trainer.Trainer</a></li>
</ul>


<h3><a id="index_j" name="index_j"></a>- j -</h3><ul>
<li>jig_type&#160;:&#160;<a class="el" href="classrl_1_1env_1_1state_1_1_jig.html#a204c876bbb1188925b9a3f2d7e63763f">rl.env.state.Jig</a></li>
<li>jigs&#160;:&#160;<a class="el" href="classrl_1_1env_1_1state_1_1_problem_state.html#ae69ebea50bb1cc9db3db8da1f048822e">rl.env.state.ProblemState</a></li>
</ul>


<h3><a id="index_l" name="index_l"></a>- l -</h3><ul>
<li>learn_iters&#160;:&#160;<a class="el" href="classrl_1_1training_1_1trainer_1_1_trainer.html#adc3380c8b2203c1873fb8e5de511c095">rl.training.trainer.Trainer</a></li>
</ul>


<h3><a id="index_m" name="index_m"></a>- m -</h3><ul>
<li>mcts&#160;:&#160;<a class="el" href="classrl_1_1training_1_1trainer_1_1_trainer.html#a426f32a6b93f28582fb77d54af312a16">rl.training.trainer.Trainer</a></li>
<li>memory&#160;:&#160;<a class="el" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent.html#aa806d28253ea490fc8b519af229bec28">rl.agents.high_level.ppo_agent.PPOAgent</a></li>
</ul>


<h3><a id="index_n" name="index_n"></a>- n -</h3><ul>
<li>n_epochs&#160;:&#160;<a class="el" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent.html#a7ba79036643adb93f11d205be1dd0b5f">rl.agents.high_level.ppo_agent.PPOAgent</a></li>
<li>n_simulations&#160;:&#160;<a class="el" href="classrl_1_1mcts_1_1mcts_1_1_m_c_t_s.html#a8f4bd2ea226660619b54bd7a3bed820f">rl.mcts.mcts.MCTS</a></li>
<li>name&#160;:&#160;<a class="el" href="classrl_1_1env_1_1state_1_1_jig_type.html#a6dddb07fa670281a85ea3ec67ec8d506">rl.env.state.JigType</a></li>
</ul>


<h3><a id="index_o" name="index_o"></a>- o -</h3><ul>
<li>optimizer&#160;:&#160;<a class="el" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_actor_network.html#a94510c3daa25640bed11a76900a888a5">rl.agents.high_level.ppo_agent.ActorNetwork</a>, <a class="el" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_critic_network.html#ad2c14eed568cf52935eda79be9e6916f">rl.agents.high_level.ppo_agent.CriticNetwork</a></li>
<li>outgoing&#160;:&#160;<a class="el" href="classrl_1_1env_1_1state_1_1_beluga.html#a227851252319a4e980f875f6b1eb50b5">rl.env.state.Beluga</a></li>
</ul>


<h3><a id="index_p" name="index_p"></a>- p -</h3><ul>
<li>parent&#160;:&#160;<a class="el" href="classrl_1_1mcts_1_1mcts__node_1_1_m_c_t_s_node.html#a998ee584a8fdd624e32a1c80b8720399">rl.mcts.mcts_node.MCTSNode</a></li>
<li>path&#160;:&#160;<a class="el" href="classrl_1_1env_1_1environment_1_1_env.html#aaeb8d08508f65b21982c7c0873f9c116">rl.env.environment.Env</a></li>
<li>policy_clip&#160;:&#160;<a class="el" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent.html#a6943862574b28a3371d19ee56455a544">rl.agents.high_level.ppo_agent.PPOAgent</a></li>
<li>ppo_agent&#160;:&#160;<a class="el" href="classrl_1_1training_1_1trainer_1_1_trainer.html#aaeda707242f803f4a3d92aa58183d78b">rl.training.trainer.Trainer</a></li>
<li>problem_count&#160;:&#160;<a class="el" href="classrl_1_1env_1_1environment_1_1_env.html#a79fa3fdcba112f48ea48a9966dd3116d">rl.env.environment.Env</a></li>
<li>problem_name&#160;:&#160;<a class="el" href="classrl_1_1env_1_1environment_1_1_env.html#abffb6a6d658716f9a823e77c3c9007a2">rl.env.environment.Env</a></li>
<li>problem_solved&#160;:&#160;<a class="el" href="classrl_1_1env_1_1state_1_1_problem_state.html#a2e8b188e6ab9501da8478eebbc783ebe">rl.env.state.ProblemState</a></li>
<li>problems_solved&#160;:&#160;<a class="el" href="classrl_1_1env_1_1environment_1_1_env.html#a52fdb33c984f2f5b997ab19423098706">rl.env.environment.Env</a></li>
<li>probs&#160;:&#160;<a class="el" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_memory.html#aba4f59ce24a7a1e276c121cf9fff1512">rl.agents.high_level.ppo_agent.PPOMemory</a></li>
<li>production_lines&#160;:&#160;<a class="el" href="classrl_1_1env_1_1state_1_1_problem_state.html#a54d9d168c4472bd0f33fecb22a3890c7">rl.env.state.ProblemState</a></li>
<li>production_lines_finished&#160;:&#160;<a class="el" href="classrl_1_1env_1_1state_1_1_problem_state.html#a3fa9e9374aa07623ea037c27195d26fe">rl.env.state.ProblemState</a></li>
</ul>


<h3><a id="index_r" name="index_r"></a>- r -</h3><ul>
<li>racks&#160;:&#160;<a class="el" href="classrl_1_1env_1_1state_1_1_problem_state.html#a1ec78c677f24987ac0778d8cab4398c5">rl.env.state.ProblemState</a></li>
<li>rewards&#160;:&#160;<a class="el" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_memory.html#acf933f33d5540126ed764ff35e0667ef">rl.agents.high_level.ppo_agent.PPOMemory</a></li>
<li>root&#160;:&#160;<a class="el" href="classrl_1_1mcts_1_1mcts_1_1_m_c_t_s.html#a11142d8d66dba17479436e590192fb90">rl.mcts.mcts.MCTS</a></li>
</ul>


<h3><a id="index_s" name="index_s"></a>- s -</h3><ul>
<li>scheduled_jigs&#160;:&#160;<a class="el" href="classrl_1_1env_1_1state_1_1_production_line.html#a3925ef8756d36cecc7b165bae63f3aa0">rl.env.state.ProductionLine</a></li>
<li>score_history&#160;:&#160;<a class="el" href="classrl_1_1training_1_1trainer_1_1_trainer.html#a1b0e2b1ca4666b1edd6707c7916f15fd">rl.training.trainer.Trainer</a></li>
<li>size&#160;:&#160;<a class="el" href="classrl_1_1env_1_1state_1_1_rack.html#adf979b16e485f70c951796bfa0361ec2">rl.env.state.Rack</a></li>
<li>size_empty&#160;:&#160;<a class="el" href="classrl_1_1env_1_1state_1_1_jig_type.html#a465438b452ca889cc9184c31f979a151">rl.env.state.JigType</a></li>
<li>size_loaded&#160;:&#160;<a class="el" href="classrl_1_1env_1_1state_1_1_jig_type.html#ab0615ed4aeb2b12c12c830f9e22340ce">rl.env.state.JigType</a></li>
<li>sorted_problems&#160;:&#160;<a class="el" href="classrl_1_1env_1_1environment_1_1_env.html#aa2551205b5c158666fe974658f89444b">rl.env.environment.Env</a></li>
<li>state&#160;:&#160;<a class="el" href="classrl_1_1env_1_1environment_1_1_env.html#a6159ac4f2691e37e74b26251dfa0cce3">rl.env.environment.Env</a>, <a class="el" href="classrl_1_1mcts_1_1mcts__node_1_1_m_c_t_s_node.html#a971fa4a5d101ac6718fc4131a0100607">rl.mcts.mcts_node.MCTSNode</a></li>
<li>states&#160;:&#160;<a class="el" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_memory.html#a0add6132e8c45fde1017f3d1b9fd62e1">rl.agents.high_level.ppo_agent.PPOMemory</a></li>
<li>step_count&#160;:&#160;<a class="el" href="classrl_1_1env_1_1environment_1_1_env.html#a02f4b1808e4564848cdb5d9962853b1b">rl.env.environment.Env</a></li>
<li>steps_per_episode&#160;:&#160;<a class="el" href="classrl_1_1training_1_1trainer_1_1_trainer.html#a3497eb76c0856c13f5ffb747a6435968">rl.training.trainer.Trainer</a></li>
</ul>


<h3><a id="index_t" name="index_t"></a>- t -</h3><ul>
<li>total_belugas&#160;:&#160;<a class="el" href="classrl_1_1env_1_1state_1_1_problem_state.html#a8757d2f3438dafcc6c03fb96116dc3db">rl.env.state.ProblemState</a></li>
<li>total_lines&#160;:&#160;<a class="el" href="classrl_1_1env_1_1state_1_1_problem_state.html#a0572124eeab50ea62588152aa334baa3">rl.env.state.ProblemState</a></li>
<li>total_reward&#160;:&#160;<a class="el" href="classrl_1_1mcts_1_1mcts__node_1_1_m_c_t_s_node.html#a58fb7e57f65c0da19b994d61b0652517">rl.mcts.mcts_node.MCTSNode</a></li>
<li>total_steps&#160;:&#160;<a class="el" href="classrl_1_1training_1_1trainer_1_1_trainer.html#a911fdcd8b62556fea6eeb7ec90785dc4">rl.training.trainer.Trainer</a></li>
<li>trailers_beluga&#160;:&#160;<a class="el" href="classrl_1_1env_1_1state_1_1_problem_state.html#a634c438942449d0a8d5d3259bceed2d2">rl.env.state.ProblemState</a></li>
<li>trailers_factory&#160;:&#160;<a class="el" href="classrl_1_1env_1_1state_1_1_problem_state.html#a388549e61b047cdb88493a251d17c8f8">rl.env.state.ProblemState</a></li>
</ul>


<h3><a id="index_v" name="index_v"></a>- v -</h3><ul>
<li>values&#160;:&#160;<a class="el" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_memory.html#a47453ce0abdb11c30dd9f8222a96b457">rl.agents.high_level.ppo_agent.PPOMemory</a></li>
<li>visits&#160;:&#160;<a class="el" href="classrl_1_1mcts_1_1mcts__node_1_1_m_c_t_s_node.html#ac95d5c05b2da87ff65a374c50772627a">rl.mcts.mcts_node.MCTSNode</a></li>
</ul>
</div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.12.0 </li>
  </ul>
</div>
</body>
</html>
