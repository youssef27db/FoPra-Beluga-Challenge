<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.12.0"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>FoPra Beluga Challenge - Reinforcement Learning Solution: rl/agents/high_level/ppo_agent.py Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<script type="text/javascript" src="clipboard.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="cookie.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript" src="darkmode_toggle.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">FoPra Beluga Challenge - Reinforcement Learning Solution<span id="projectnumber">&#160;v1.0</span>
   </div>
   <div id="projectbrief">Deep Reinforcement Learning solution for the Beluga Challenge shipping container optimization problem using PPO and MCTS</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.12.0 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() { codefold.init(0); });
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search',true);
  $(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function(){initNavTree('ppo__agent_8py_source.html',''); initResizable(true); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div class="header">
  <div class="headertitle"><div class="title">ppo_agent.py</div></div>
</div><!--header-->
<div class="contents">
<a href="ppo__agent_8py.html">Go to the documentation of this file.</a><div class="fragment"><div class="line"><a id="l00001" name="l00001"></a><span class="lineno"><a class="line" href="namespacerl_1_1agents_1_1high__level_1_1ppo__agent.html">    1</a></span><span class="keyword">import</span> os</div>
<div class="line"><a id="l00002" name="l00002"></a><span class="lineno">    2</span><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div>
<div class="line"><a id="l00003" name="l00003"></a><span class="lineno">    3</span><span class="keyword">import</span> torch <span class="keyword">as</span> T</div>
<div class="line"><a id="l00004" name="l00004"></a><span class="lineno">    4</span><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</div>
<div class="line"><a id="l00005" name="l00005"></a><span class="lineno">    5</span><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</div>
<div class="line"><a id="l00006" name="l00006"></a><span class="lineno">    6</span><span class="keyword">from</span> torch.distributions.categorical <span class="keyword">import</span> Categorical</div>
<div class="line"><a id="l00007" name="l00007"></a><span class="lineno">    7</span> </div>
<div class="foldopen" id="foldopen00008" data-start="" data-end="">
<div class="line"><a id="l00008" name="l00008"></a><span class="lineno"><a class="line" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_memory.html">    8</a></span><span class="keyword">class </span><a class="code hl_class" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_memory.html">PPOMemory</a>:</div>
<div class="line"><a id="l00009" name="l00009"></a><span class="lineno">    9</span>    <span class="stringliteral">&quot;&quot;&quot;!</span></div>
<div class="line"><a id="l00010" name="l00010"></a><span class="lineno">   10</span><span class="stringliteral">    @brief Memory buffer for storing PPO training experiences</span></div>
<div class="line"><a id="l00011" name="l00011"></a><span class="lineno">   11</span><span class="stringliteral">    </span></div>
<div class="line"><a id="l00012" name="l00012"></a><span class="lineno">   12</span><span class="stringliteral">    This class manages the storage and retrieval of experiences for PPO training,</span></div>
<div class="line"><a id="l00013" name="l00013"></a><span class="lineno">   13</span><span class="stringliteral">    including states, actions, probabilities, values, rewards, and done flags.</span></div>
<div class="line"><a id="l00014" name="l00014"></a><span class="lineno">   14</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><a id="l00015" name="l00015"></a><span class="lineno">   15</span>    </div>
<div class="foldopen" id="foldopen00016" data-start="" data-end="">
<div class="line"><a id="l00016" name="l00016"></a><span class="lineno"><a class="line" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_memory.html#a4be12d895d6566a136a7e7d3a437da6e">   16</a></span>    <span class="keyword">def </span><a class="code hl_function" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_memory.html#a4be12d895d6566a136a7e7d3a437da6e">__init__</a>(self, batch_size):</div>
<div class="line"><a id="l00017" name="l00017"></a><span class="lineno">   17</span>        <span class="stringliteral">&quot;&quot;&quot;!</span></div>
<div class="line"><a id="l00018" name="l00018"></a><span class="lineno">   18</span><span class="stringliteral">        @brief Initialize the PPO memory buffer</span></div>
<div class="line"><a id="l00019" name="l00019"></a><span class="lineno">   19</span><span class="stringliteral">        @param batch_size Size of batches for training</span></div>
<div class="line"><a id="l00020" name="l00020"></a><span class="lineno">   20</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><a id="l00021" name="l00021"></a><span class="lineno"><a class="line" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_memory.html#a0add6132e8c45fde1017f3d1b9fd62e1">   21</a></span>        self.<a class="code hl_variable" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_memory.html#a0add6132e8c45fde1017f3d1b9fd62e1">states</a> = []</div>
<div class="line"><a id="l00022" name="l00022"></a><span class="lineno"><a class="line" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_memory.html#aba4f59ce24a7a1e276c121cf9fff1512">   22</a></span>        self.<a class="code hl_variable" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_memory.html#aba4f59ce24a7a1e276c121cf9fff1512">probs</a> = []</div>
<div class="line"><a id="l00023" name="l00023"></a><span class="lineno"><a class="line" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_memory.html#a47453ce0abdb11c30dd9f8222a96b457">   23</a></span>        self.<a class="code hl_variable" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_memory.html#a47453ce0abdb11c30dd9f8222a96b457">values</a> = []</div>
<div class="line"><a id="l00024" name="l00024"></a><span class="lineno"><a class="line" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_memory.html#a3bf4561f4eb99d3693f9128ae0522b69">   24</a></span>        self.<a class="code hl_variable" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_memory.html#a3bf4561f4eb99d3693f9128ae0522b69">actions</a> = []</div>
<div class="line"><a id="l00025" name="l00025"></a><span class="lineno"><a class="line" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_memory.html#acf933f33d5540126ed764ff35e0667ef">   25</a></span>        self.<a class="code hl_variable" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_memory.html#acf933f33d5540126ed764ff35e0667ef">rewards</a> = []</div>
<div class="line"><a id="l00026" name="l00026"></a><span class="lineno"><a class="line" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_memory.html#a0e9efad74c28d7fd7e7bd0fda0257cac">   26</a></span>        self.<a class="code hl_variable" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_memory.html#a0e9efad74c28d7fd7e7bd0fda0257cac">dones</a> = []</div>
<div class="line"><a id="l00027" name="l00027"></a><span class="lineno">   27</span> </div>
<div class="line"><a id="l00028" name="l00028"></a><span class="lineno"><a class="line" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_memory.html#a0c97a17d1a3dd1bcfbe8bc82655dee63">   28</a></span>        self.<a class="code hl_variable" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_memory.html#a0c97a17d1a3dd1bcfbe8bc82655dee63">batch_size</a> = batch_size</div>
<div class="line"><a id="l00029" name="l00029"></a><span class="lineno">   29</span> </div>
</div>
<div class="foldopen" id="foldopen00030" data-start="" data-end="">
<div class="line"><a id="l00030" name="l00030"></a><span class="lineno"><a class="line" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_memory.html#a4a87d310ee11c3ce1d58da34eb7b7d03">   30</a></span>    <span class="keyword">def </span><a class="code hl_function" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_memory.html#a4a87d310ee11c3ce1d58da34eb7b7d03">generate_batches</a>(self):</div>
<div class="line"><a id="l00031" name="l00031"></a><span class="lineno">   31</span>        <span class="stringliteral">&quot;&quot;&quot;!</span></div>
<div class="line"><a id="l00032" name="l00032"></a><span class="lineno">   32</span><span class="stringliteral">        @brief Generate randomized training batches from stored experiences</span></div>
<div class="line"><a id="l00033" name="l00033"></a><span class="lineno">   33</span><span class="stringliteral">        @return Tuple containing arrays of states, actions, probabilities, values, rewards, dones, and batch indices</span></div>
<div class="line"><a id="l00034" name="l00034"></a><span class="lineno">   34</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><a id="l00035" name="l00035"></a><span class="lineno">   35</span>        n_states = len(self.<a class="code hl_variable" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_memory.html#a0add6132e8c45fde1017f3d1b9fd62e1">states</a>)</div>
<div class="line"><a id="l00036" name="l00036"></a><span class="lineno">   36</span>        batch_start = np.arange(0, n_states, self.<a class="code hl_variable" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_memory.html#a0c97a17d1a3dd1bcfbe8bc82655dee63">batch_size</a>)</div>
<div class="line"><a id="l00037" name="l00037"></a><span class="lineno">   37</span>        indices = np.arange(n_states, dtype=np.int64)</div>
<div class="line"><a id="l00038" name="l00038"></a><span class="lineno">   38</span>        np.random.shuffle(indices)</div>
<div class="line"><a id="l00039" name="l00039"></a><span class="lineno">   39</span>        batches = [indices[i:i+self.<a class="code hl_variable" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_memory.html#a0c97a17d1a3dd1bcfbe8bc82655dee63">batch_size</a>] <span class="keywordflow">for</span> i <span class="keywordflow">in</span> batch_start]</div>
<div class="line"><a id="l00040" name="l00040"></a><span class="lineno">   40</span> </div>
<div class="line"><a id="l00041" name="l00041"></a><span class="lineno">   41</span>        <span class="keywordflow">return</span> np.array(self.<a class="code hl_variable" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_memory.html#a0add6132e8c45fde1017f3d1b9fd62e1">states</a>), np.array(self.<a class="code hl_variable" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_memory.html#a3bf4561f4eb99d3693f9128ae0522b69">actions</a>),\</div>
<div class="line"><a id="l00042" name="l00042"></a><span class="lineno">   42</span>            np.array(self.<a class="code hl_variable" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_memory.html#aba4f59ce24a7a1e276c121cf9fff1512">probs</a>), np.array(self.<a class="code hl_variable" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_memory.html#a47453ce0abdb11c30dd9f8222a96b457">values</a>),\</div>
<div class="line"><a id="l00043" name="l00043"></a><span class="lineno">   43</span>            np.array(self.<a class="code hl_variable" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_memory.html#acf933f33d5540126ed764ff35e0667ef">rewards</a>), np.array(self.<a class="code hl_variable" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_memory.html#a0e9efad74c28d7fd7e7bd0fda0257cac">dones</a>),\</div>
<div class="line"><a id="l00044" name="l00044"></a><span class="lineno">   44</span>            batches</div>
<div class="line"><a id="l00045" name="l00045"></a><span class="lineno">   45</span> </div>
</div>
<div class="foldopen" id="foldopen00046" data-start="" data-end="">
<div class="line"><a id="l00046" name="l00046"></a><span class="lineno"><a class="line" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_memory.html#acb69a1ceca60755d44ff61f0b7eb4d93">   46</a></span>    <span class="keyword">def </span><a class="code hl_function" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_memory.html#acb69a1ceca60755d44ff61f0b7eb4d93">store_memory</a>(self, state, action, probs, values, reward, done):</div>
<div class="line"><a id="l00047" name="l00047"></a><span class="lineno">   47</span>        <span class="stringliteral">&quot;&quot;&quot;!</span></div>
<div class="line"><a id="l00048" name="l00048"></a><span class="lineno">   48</span><span class="stringliteral">        @brief Store a single experience in the memory buffer</span></div>
<div class="line"><a id="l00049" name="l00049"></a><span class="lineno">   49</span><span class="stringliteral">        @param state Current state observation</span></div>
<div class="line"><a id="l00050" name="l00050"></a><span class="lineno">   50</span><span class="stringliteral">        @param action Action taken</span></div>
<div class="line"><a id="l00051" name="l00051"></a><span class="lineno">   51</span><span class="stringliteral">        @param probs Action probability from policy</span></div>
<div class="line"><a id="l00052" name="l00052"></a><span class="lineno">   52</span><span class="stringliteral">        @param values State value estimate</span></div>
<div class="line"><a id="l00053" name="l00053"></a><span class="lineno">   53</span><span class="stringliteral">        @param reward Received reward</span></div>
<div class="line"><a id="l00054" name="l00054"></a><span class="lineno">   54</span><span class="stringliteral">        @param done Episode termination flag</span></div>
<div class="line"><a id="l00055" name="l00055"></a><span class="lineno">   55</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><a id="l00056" name="l00056"></a><span class="lineno">   56</span>        self.<a class="code hl_variable" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_memory.html#a0add6132e8c45fde1017f3d1b9fd62e1">states</a>.append(state)</div>
<div class="line"><a id="l00057" name="l00057"></a><span class="lineno">   57</span>        self.<a class="code hl_variable" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_memory.html#a3bf4561f4eb99d3693f9128ae0522b69">actions</a>.append(action)</div>
<div class="line"><a id="l00058" name="l00058"></a><span class="lineno">   58</span>        self.<a class="code hl_variable" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_memory.html#aba4f59ce24a7a1e276c121cf9fff1512">probs</a>.append(probs)</div>
<div class="line"><a id="l00059" name="l00059"></a><span class="lineno">   59</span>        self.<a class="code hl_variable" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_memory.html#a47453ce0abdb11c30dd9f8222a96b457">values</a>.append(values)</div>
<div class="line"><a id="l00060" name="l00060"></a><span class="lineno">   60</span>        self.<a class="code hl_variable" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_memory.html#acf933f33d5540126ed764ff35e0667ef">rewards</a>.append(reward)</div>
<div class="line"><a id="l00061" name="l00061"></a><span class="lineno">   61</span>        self.<a class="code hl_variable" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_memory.html#a0e9efad74c28d7fd7e7bd0fda0257cac">dones</a>.append(done)</div>
<div class="line"><a id="l00062" name="l00062"></a><span class="lineno">   62</span> </div>
</div>
<div class="foldopen" id="foldopen00063" data-start="" data-end="">
<div class="line"><a id="l00063" name="l00063"></a><span class="lineno"><a class="line" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_memory.html#a0b27fdd1b6d3d971bc034b616b58f7d7">   63</a></span>    <span class="keyword">def </span><a class="code hl_function" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_memory.html#a0b27fdd1b6d3d971bc034b616b58f7d7">clear_memory</a>(self):</div>
<div class="line"><a id="l00064" name="l00064"></a><span class="lineno">   64</span>        <span class="stringliteral">&quot;&quot;&quot;!</span></div>
<div class="line"><a id="l00065" name="l00065"></a><span class="lineno">   65</span><span class="stringliteral">        @brief Clear all stored experiences from memory</span></div>
<div class="line"><a id="l00066" name="l00066"></a><span class="lineno">   66</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><a id="l00067" name="l00067"></a><span class="lineno">   67</span>        self.<a class="code hl_variable" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_memory.html#a0add6132e8c45fde1017f3d1b9fd62e1">states</a> = []</div>
<div class="line"><a id="l00068" name="l00068"></a><span class="lineno">   68</span>        self.<a class="code hl_variable" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_memory.html#a3bf4561f4eb99d3693f9128ae0522b69">actions</a> = []</div>
<div class="line"><a id="l00069" name="l00069"></a><span class="lineno">   69</span>        self.<a class="code hl_variable" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_memory.html#aba4f59ce24a7a1e276c121cf9fff1512">probs</a> = []</div>
<div class="line"><a id="l00070" name="l00070"></a><span class="lineno">   70</span>        self.<a class="code hl_variable" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_memory.html#a47453ce0abdb11c30dd9f8222a96b457">values</a> = []</div>
<div class="line"><a id="l00071" name="l00071"></a><span class="lineno">   71</span>        self.<a class="code hl_variable" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_memory.html#acf933f33d5540126ed764ff35e0667ef">rewards</a> = []</div>
<div class="line"><a id="l00072" name="l00072"></a><span class="lineno">   72</span>        self.<a class="code hl_variable" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_memory.html#a0e9efad74c28d7fd7e7bd0fda0257cac">dones</a> = []</div>
<div class="line"><a id="l00073" name="l00073"></a><span class="lineno">   73</span> </div>
<div class="line"><a id="l00074" name="l00074"></a><span class="lineno">   74</span> </div>
</div>
</div>
<div class="foldopen" id="foldopen00075" data-start="" data-end="">
<div class="line"><a id="l00075" name="l00075"></a><span class="lineno"><a class="line" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_actor_network.html">   75</a></span><span class="keyword">class </span><a class="code hl_class" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_actor_network.html">ActorNetwork</a>(nn.Module):</div>
<div class="line"><a id="l00076" name="l00076"></a><span class="lineno">   76</span>    <span class="stringliteral">&quot;&quot;&quot;!</span></div>
<div class="line"><a id="l00077" name="l00077"></a><span class="lineno">   77</span><span class="stringliteral">    @brief Actor network for PPO agent</span></div>
<div class="line"><a id="l00078" name="l00078"></a><span class="lineno">   78</span><span class="stringliteral">    </span></div>
<div class="line"><a id="l00079" name="l00079"></a><span class="lineno">   79</span><span class="stringliteral">    Neural network that outputs action probabilities given a state.</span></div>
<div class="line"><a id="l00080" name="l00080"></a><span class="lineno">   80</span><span class="stringliteral">    Uses a categorical distribution for discrete action spaces.</span></div>
<div class="line"><a id="l00081" name="l00081"></a><span class="lineno">   81</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><a id="l00082" name="l00082"></a><span class="lineno">   82</span>    </div>
<div class="foldopen" id="foldopen00083" data-start="" data-end="">
<div class="line"><a id="l00083" name="l00083"></a><span class="lineno"><a class="line" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_actor_network.html#aee7d89c100fcc1aee1870322de45a72d">   83</a></span>    <span class="keyword">def </span><a class="code hl_function" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_actor_network.html#aee7d89c100fcc1aee1870322de45a72d">__init__</a>(self, n_actions, input_dims, alpha, fc1dims=256, fc2dims=256, fc3dims=128, chkpt_dir=&#39;tmp/ppo&#39;, name = &#39;ppo&#39;):</div>
<div class="line"><a id="l00084" name="l00084"></a><span class="lineno">   84</span>        <span class="stringliteral">&quot;&quot;&quot;!</span></div>
<div class="line"><a id="l00085" name="l00085"></a><span class="lineno">   85</span><span class="stringliteral">        @brief Initialize the actor network</span></div>
<div class="line"><a id="l00086" name="l00086"></a><span class="lineno">   86</span><span class="stringliteral">        @param n_actions Number of possible actions</span></div>
<div class="line"><a id="l00087" name="l00087"></a><span class="lineno">   87</span><span class="stringliteral">        @param input_dims Dimension of input state space</span></div>
<div class="line"><a id="l00088" name="l00088"></a><span class="lineno">   88</span><span class="stringliteral">        @param alpha Learning rate for optimization</span></div>
<div class="line"><a id="l00089" name="l00089"></a><span class="lineno">   89</span><span class="stringliteral">        @param fc1dims Number of neurons in first hidden layer</span></div>
<div class="line"><a id="l00090" name="l00090"></a><span class="lineno">   90</span><span class="stringliteral">        @param fc2dims Number of neurons in second hidden layer  </span></div>
<div class="line"><a id="l00091" name="l00091"></a><span class="lineno">   91</span><span class="stringliteral">        @param fc3dims Number of neurons in third hidden layer</span></div>
<div class="line"><a id="l00092" name="l00092"></a><span class="lineno">   92</span><span class="stringliteral">        @param chkpt_dir Directory for saving checkpoints</span></div>
<div class="line"><a id="l00093" name="l00093"></a><span class="lineno">   93</span><span class="stringliteral">        @param name Model name for checkpoint files</span></div>
<div class="line"><a id="l00094" name="l00094"></a><span class="lineno">   94</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><a id="l00095" name="l00095"></a><span class="lineno">   95</span>        super(ActorNetwork, self).<a class="code hl_function" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_actor_network.html#aee7d89c100fcc1aee1870322de45a72d">__init__</a>()</div>
<div class="line"><a id="l00096" name="l00096"></a><span class="lineno">   96</span> </div>
<div class="line"><a id="l00097" name="l00097"></a><span class="lineno"><a class="line" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_actor_network.html#a67e4554ca3dd016844a0073df5ff6cbf">   97</a></span>        self.<a class="code hl_variable" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_actor_network.html#a67e4554ca3dd016844a0073df5ff6cbf">checkpoint_file</a> = os.path.join(chkpt_dir, <span class="stringliteral">&#39;actor_torch_&#39;</span> + name)</div>
<div class="line"><a id="l00098" name="l00098"></a><span class="lineno"><a class="line" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_actor_network.html#a28ce44f0321d73d4cbcef057607fcf16">   98</a></span>        self.<a class="code hl_variable" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_actor_network.html#a28ce44f0321d73d4cbcef057607fcf16">actor</a> = nn.Sequential(nn.Linear(input_dims, fc1dims), nn.ReLU(),</div>
<div class="line"><a id="l00099" name="l00099"></a><span class="lineno">   99</span>                                   nn.Linear(fc1dims, fc2dims), nn.ReLU(),</div>
<div class="line"><a id="l00100" name="l00100"></a><span class="lineno">  100</span>                                   nn.Linear(fc2dims, fc3dims), nn.ReLU(),</div>
<div class="line"><a id="l00101" name="l00101"></a><span class="lineno">  101</span>                                   nn.Linear(fc3dims, n_actions), nn.Softmax(dim=-1))</div>
<div class="line"><a id="l00102" name="l00102"></a><span class="lineno">  102</span> </div>
<div class="line"><a id="l00103" name="l00103"></a><span class="lineno"><a class="line" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_actor_network.html#a94510c3daa25640bed11a76900a888a5">  103</a></span>        self.<a class="code hl_variable" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_actor_network.html#a94510c3daa25640bed11a76900a888a5">optimizer</a> = optim.Adam(self.parameters(), lr=alpha)</div>
<div class="line"><a id="l00104" name="l00104"></a><span class="lineno"><a class="line" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_actor_network.html#a1a3c826967f0c48bd422494b0a61aa35">  104</a></span>        self.<a class="code hl_variable" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_actor_network.html#a1a3c826967f0c48bd422494b0a61aa35">device</a> = T.device(<span class="stringliteral">&#39;cuda&#39;</span> <span class="keywordflow">if</span> T.cuda.is_available() <span class="keywordflow">else</span> <span class="stringliteral">&#39;cpu&#39;</span>)</div>
<div class="line"><a id="l00105" name="l00105"></a><span class="lineno">  105</span>        self.to(self.<a class="code hl_variable" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_actor_network.html#a1a3c826967f0c48bd422494b0a61aa35">device</a>)</div>
<div class="line"><a id="l00106" name="l00106"></a><span class="lineno">  106</span> </div>
</div>
<div class="foldopen" id="foldopen00107" data-start="" data-end="">
<div class="line"><a id="l00107" name="l00107"></a><span class="lineno"><a class="line" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_actor_network.html#a205adbf70f3a9fa366ab0fcdee380333">  107</a></span>    <span class="keyword">def </span><a class="code hl_function" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_actor_network.html#a205adbf70f3a9fa366ab0fcdee380333">forward</a>(self, state):</div>
<div class="line"><a id="l00108" name="l00108"></a><span class="lineno">  108</span>        <span class="stringliteral">&quot;&quot;&quot;!</span></div>
<div class="line"><a id="l00109" name="l00109"></a><span class="lineno">  109</span><span class="stringliteral">        @brief Forward pass through the actor network</span></div>
<div class="line"><a id="l00110" name="l00110"></a><span class="lineno">  110</span><span class="stringliteral">        @param state Input state tensor</span></div>
<div class="line"><a id="l00111" name="l00111"></a><span class="lineno">  111</span><span class="stringliteral">        @return Categorical distribution over actions</span></div>
<div class="line"><a id="l00112" name="l00112"></a><span class="lineno">  112</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><a id="l00113" name="l00113"></a><span class="lineno">  113</span>        dist = self.<a class="code hl_variable" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_actor_network.html#a28ce44f0321d73d4cbcef057607fcf16">actor</a>(state)</div>
<div class="line"><a id="l00114" name="l00114"></a><span class="lineno">  114</span>        dist = Categorical(dist)</div>
<div class="line"><a id="l00115" name="l00115"></a><span class="lineno">  115</span> </div>
<div class="line"><a id="l00116" name="l00116"></a><span class="lineno">  116</span>        <span class="keywordflow">return</span> dist</div>
<div class="line"><a id="l00117" name="l00117"></a><span class="lineno">  117</span> </div>
</div>
<div class="foldopen" id="foldopen00118" data-start="" data-end="">
<div class="line"><a id="l00118" name="l00118"></a><span class="lineno"><a class="line" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_actor_network.html#a8bc09dc4a05f9d935d74e45d2d7e459c">  118</a></span>    <span class="keyword">def </span><a class="code hl_function" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_actor_network.html#a8bc09dc4a05f9d935d74e45d2d7e459c">save_checkpoint</a>(self):</div>
<div class="line"><a id="l00119" name="l00119"></a><span class="lineno">  119</span>        <span class="stringliteral">&quot;&quot;&quot;!</span></div>
<div class="line"><a id="l00120" name="l00120"></a><span class="lineno">  120</span><span class="stringliteral">        @brief Save the current model state to checkpoint file</span></div>
<div class="line"><a id="l00121" name="l00121"></a><span class="lineno">  121</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><a id="l00122" name="l00122"></a><span class="lineno">  122</span>        T.save(self.state_dict(), self.<a class="code hl_variable" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_actor_network.html#a67e4554ca3dd016844a0073df5ff6cbf">checkpoint_file</a>)</div>
<div class="line"><a id="l00123" name="l00123"></a><span class="lineno">  123</span> </div>
</div>
<div class="foldopen" id="foldopen00124" data-start="" data-end="">
<div class="line"><a id="l00124" name="l00124"></a><span class="lineno"><a class="line" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_actor_network.html#a0f4ea4666192124613d9c1073cd5951c">  124</a></span>    <span class="keyword">def </span><a class="code hl_function" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_actor_network.html#a0f4ea4666192124613d9c1073cd5951c">load_checkpoint</a>(self):</div>
<div class="line"><a id="l00125" name="l00125"></a><span class="lineno">  125</span>        <span class="stringliteral">&quot;&quot;&quot;!</span></div>
<div class="line"><a id="l00126" name="l00126"></a><span class="lineno">  126</span><span class="stringliteral">        @brief Load model state from checkpoint file</span></div>
<div class="line"><a id="l00127" name="l00127"></a><span class="lineno">  127</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><a id="l00128" name="l00128"></a><span class="lineno">  128</span>        self.load_state_dict(T.load(self.<a class="code hl_variable" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_actor_network.html#a67e4554ca3dd016844a0073df5ff6cbf">checkpoint_file</a>))</div>
<div class="line"><a id="l00129" name="l00129"></a><span class="lineno">  129</span> </div>
<div class="line"><a id="l00130" name="l00130"></a><span class="lineno">  130</span> </div>
</div>
</div>
<div class="foldopen" id="foldopen00131" data-start="" data-end="">
<div class="line"><a id="l00131" name="l00131"></a><span class="lineno"><a class="line" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_critic_network.html">  131</a></span><span class="keyword">class </span><a class="code hl_class" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_critic_network.html">CriticNetwork</a>(nn.Module):</div>
<div class="line"><a id="l00132" name="l00132"></a><span class="lineno">  132</span>    <span class="stringliteral">&quot;&quot;&quot;!</span></div>
<div class="line"><a id="l00133" name="l00133"></a><span class="lineno">  133</span><span class="stringliteral">    @brief Critic network for PPO agent</span></div>
<div class="line"><a id="l00134" name="l00134"></a><span class="lineno">  134</span><span class="stringliteral">    </span></div>
<div class="line"><a id="l00135" name="l00135"></a><span class="lineno">  135</span><span class="stringliteral">    Neural network that estimates the value function V(s) for a given state.</span></div>
<div class="line"><a id="l00136" name="l00136"></a><span class="lineno">  136</span><span class="stringliteral">    Used to compute advantages in the PPO algorithm.</span></div>
<div class="line"><a id="l00137" name="l00137"></a><span class="lineno">  137</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><a id="l00138" name="l00138"></a><span class="lineno">  138</span>    </div>
<div class="foldopen" id="foldopen00139" data-start="" data-end="">
<div class="line"><a id="l00139" name="l00139"></a><span class="lineno"><a class="line" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_critic_network.html#ae3f0e45a7ac28221a69ed2d0a91d5283">  139</a></span>    <span class="keyword">def </span><a class="code hl_function" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_critic_network.html#ae3f0e45a7ac28221a69ed2d0a91d5283">__init__</a>(self, input_dims, alpha, fc1dims=256, fc2dims=256, fc3dims=128, chkpt_dir=&#39;tmp/ppo&#39;, name = &#39;ppo&#39;):</div>
<div class="line"><a id="l00140" name="l00140"></a><span class="lineno">  140</span>        <span class="stringliteral">&quot;&quot;&quot;!</span></div>
<div class="line"><a id="l00141" name="l00141"></a><span class="lineno">  141</span><span class="stringliteral">        @brief Initialize the critic network</span></div>
<div class="line"><a id="l00142" name="l00142"></a><span class="lineno">  142</span><span class="stringliteral">        @param input_dims Dimension of input state space</span></div>
<div class="line"><a id="l00143" name="l00143"></a><span class="lineno">  143</span><span class="stringliteral">        @param alpha Learning rate for optimization</span></div>
<div class="line"><a id="l00144" name="l00144"></a><span class="lineno">  144</span><span class="stringliteral">        @param fc1dims Number of neurons in first hidden layer</span></div>
<div class="line"><a id="l00145" name="l00145"></a><span class="lineno">  145</span><span class="stringliteral">        @param fc2dims Number of neurons in second hidden layer</span></div>
<div class="line"><a id="l00146" name="l00146"></a><span class="lineno">  146</span><span class="stringliteral">        @param fc3dims Number of neurons in third hidden layer</span></div>
<div class="line"><a id="l00147" name="l00147"></a><span class="lineno">  147</span><span class="stringliteral">        @param chkpt_dir Directory for saving checkpoints</span></div>
<div class="line"><a id="l00148" name="l00148"></a><span class="lineno">  148</span><span class="stringliteral">        @param name Model name for checkpoint files</span></div>
<div class="line"><a id="l00149" name="l00149"></a><span class="lineno">  149</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><a id="l00150" name="l00150"></a><span class="lineno">  150</span>        super(CriticNetwork, self).<a class="code hl_function" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_critic_network.html#ae3f0e45a7ac28221a69ed2d0a91d5283">__init__</a>()</div>
<div class="line"><a id="l00151" name="l00151"></a><span class="lineno">  151</span> </div>
<div class="line"><a id="l00152" name="l00152"></a><span class="lineno"><a class="line" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_critic_network.html#a0f8199be7d8c7e801ff0b88336b96213">  152</a></span>        self.<a class="code hl_variable" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_critic_network.html#a0f8199be7d8c7e801ff0b88336b96213">checkpoint_file</a> = os.path.join(chkpt_dir, <span class="stringliteral">&#39;critic_torch_&#39;</span> + name)</div>
<div class="line"><a id="l00153" name="l00153"></a><span class="lineno"><a class="line" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_critic_network.html#a824b1eed500fc53536c0f7e01d176988">  153</a></span>        self.<a class="code hl_variable" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_critic_network.html#a824b1eed500fc53536c0f7e01d176988">critic</a> = nn.Sequential(nn.Linear(input_dims, fc1dims), nn.ReLU(),</div>
<div class="line"><a id="l00154" name="l00154"></a><span class="lineno">  154</span>                                    nn.Linear(fc1dims, fc2dims), nn.ReLU(),</div>
<div class="line"><a id="l00155" name="l00155"></a><span class="lineno">  155</span>                                    nn.Linear(fc2dims, fc3dims), nn.ReLU(),</div>
<div class="line"><a id="l00156" name="l00156"></a><span class="lineno">  156</span>                                    nn.Linear(fc3dims, 1))</div>
<div class="line"><a id="l00157" name="l00157"></a><span class="lineno">  157</span> </div>
<div class="line"><a id="l00158" name="l00158"></a><span class="lineno"><a class="line" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_critic_network.html#ad2c14eed568cf52935eda79be9e6916f">  158</a></span>        self.<a class="code hl_variable" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_critic_network.html#ad2c14eed568cf52935eda79be9e6916f">optimizer</a> = optim.Adam(self.parameters(), lr=alpha)</div>
<div class="line"><a id="l00159" name="l00159"></a><span class="lineno"><a class="line" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_critic_network.html#a83eec626281fcdfb93996bb50aee40a8">  159</a></span>        self.<a class="code hl_variable" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_critic_network.html#a83eec626281fcdfb93996bb50aee40a8">device</a> = T.device(<span class="stringliteral">&#39;cuda&#39;</span> <span class="keywordflow">if</span> T.cuda.is_available() <span class="keywordflow">else</span> <span class="stringliteral">&#39;cpu&#39;</span>)</div>
<div class="line"><a id="l00160" name="l00160"></a><span class="lineno">  160</span>        self.to(self.<a class="code hl_variable" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_critic_network.html#a83eec626281fcdfb93996bb50aee40a8">device</a>)</div>
<div class="line"><a id="l00161" name="l00161"></a><span class="lineno">  161</span> </div>
</div>
<div class="foldopen" id="foldopen00162" data-start="" data-end="">
<div class="line"><a id="l00162" name="l00162"></a><span class="lineno"><a class="line" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_critic_network.html#ae4e70fa5ae609b2ea791905c0c7c37bc">  162</a></span>    <span class="keyword">def </span><a class="code hl_function" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_critic_network.html#ae4e70fa5ae609b2ea791905c0c7c37bc">forward</a>(self, state):</div>
<div class="line"><a id="l00163" name="l00163"></a><span class="lineno">  163</span>        <span class="stringliteral">&quot;&quot;&quot;!</span></div>
<div class="line"><a id="l00164" name="l00164"></a><span class="lineno">  164</span><span class="stringliteral">        @brief Forward pass through the critic network</span></div>
<div class="line"><a id="l00165" name="l00165"></a><span class="lineno">  165</span><span class="stringliteral">        @param state Input state tensor</span></div>
<div class="line"><a id="l00166" name="l00166"></a><span class="lineno">  166</span><span class="stringliteral">        @return Value estimate for the given state</span></div>
<div class="line"><a id="l00167" name="l00167"></a><span class="lineno">  167</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><a id="l00168" name="l00168"></a><span class="lineno">  168</span>        value = self.<a class="code hl_variable" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_critic_network.html#a824b1eed500fc53536c0f7e01d176988">critic</a>(state)</div>
<div class="line"><a id="l00169" name="l00169"></a><span class="lineno">  169</span> </div>
<div class="line"><a id="l00170" name="l00170"></a><span class="lineno">  170</span>        <span class="keywordflow">return</span> value</div>
<div class="line"><a id="l00171" name="l00171"></a><span class="lineno">  171</span> </div>
</div>
<div class="foldopen" id="foldopen00172" data-start="" data-end="">
<div class="line"><a id="l00172" name="l00172"></a><span class="lineno"><a class="line" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_critic_network.html#a56a2a9b7dd1e46f6cca7cd7f3b18e649">  172</a></span>    <span class="keyword">def </span><a class="code hl_function" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_critic_network.html#a56a2a9b7dd1e46f6cca7cd7f3b18e649">save_checkpoint</a>(self):</div>
<div class="line"><a id="l00173" name="l00173"></a><span class="lineno">  173</span>        <span class="stringliteral">&quot;&quot;&quot;!</span></div>
<div class="line"><a id="l00174" name="l00174"></a><span class="lineno">  174</span><span class="stringliteral">        @brief Save the current model state to checkpoint file</span></div>
<div class="line"><a id="l00175" name="l00175"></a><span class="lineno">  175</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><a id="l00176" name="l00176"></a><span class="lineno">  176</span>        T.save(self.state_dict(), self.<a class="code hl_variable" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_critic_network.html#a0f8199be7d8c7e801ff0b88336b96213">checkpoint_file</a>)</div>
<div class="line"><a id="l00177" name="l00177"></a><span class="lineno">  177</span> </div>
</div>
<div class="foldopen" id="foldopen00178" data-start="" data-end="">
<div class="line"><a id="l00178" name="l00178"></a><span class="lineno"><a class="line" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_critic_network.html#acd6e3b7f5abc211d93a99509914e248a">  178</a></span>    <span class="keyword">def </span><a class="code hl_function" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_critic_network.html#acd6e3b7f5abc211d93a99509914e248a">load_checkpoint</a>(self):</div>
<div class="line"><a id="l00179" name="l00179"></a><span class="lineno">  179</span>        <span class="stringliteral">&quot;&quot;&quot;!</span></div>
<div class="line"><a id="l00180" name="l00180"></a><span class="lineno">  180</span><span class="stringliteral">        @brief Load model state from checkpoint file</span></div>
<div class="line"><a id="l00181" name="l00181"></a><span class="lineno">  181</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><a id="l00182" name="l00182"></a><span class="lineno">  182</span>        self.load_state_dict(T.load(self.<a class="code hl_variable" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_critic_network.html#a0f8199be7d8c7e801ff0b88336b96213">checkpoint_file</a>))</div>
<div class="line"><a id="l00183" name="l00183"></a><span class="lineno">  183</span> </div>
<div class="line"><a id="l00184" name="l00184"></a><span class="lineno">  184</span> </div>
</div>
</div>
<div class="foldopen" id="foldopen00185" data-start="" data-end="">
<div class="line"><a id="l00185" name="l00185"></a><span class="lineno"><a class="line" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent.html">  185</a></span><span class="keyword">class </span><a class="code hl_class" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent.html">PPOAgent</a>:</div>
<div class="line"><a id="l00186" name="l00186"></a><span class="lineno">  186</span>    <span class="stringliteral">&quot;&quot;&quot;!</span></div>
<div class="line"><a id="l00187" name="l00187"></a><span class="lineno">  187</span><span class="stringliteral">    @brief Proximal Policy Optimization (PPO) agent implementation</span></div>
<div class="line"><a id="l00188" name="l00188"></a><span class="lineno">  188</span><span class="stringliteral">    </span></div>
<div class="line"><a id="l00189" name="l00189"></a><span class="lineno">  189</span><span class="stringliteral">    This class implements the PPO algorithm for reinforcement learning.</span></div>
<div class="line"><a id="l00190" name="l00190"></a><span class="lineno">  190</span><span class="stringliteral">    It uses an actor-critic architecture with clipped probability ratios</span></div>
<div class="line"><a id="l00191" name="l00191"></a><span class="lineno">  191</span><span class="stringliteral">    to ensure stable policy updates.</span></div>
<div class="line"><a id="l00192" name="l00192"></a><span class="lineno">  192</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><a id="l00193" name="l00193"></a><span class="lineno">  193</span>    </div>
<div class="foldopen" id="foldopen00194" data-start="" data-end="">
<div class="line"><a id="l00194" name="l00194"></a><span class="lineno"><a class="line" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent.html#a2a0c96183d523d54d8203e10dcb129a3">  194</a></span>    <span class="keyword">def </span><a class="code hl_function" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent.html#a2a0c96183d523d54d8203e10dcb129a3">__init__</a>(self, input_dims, n_actions, gamma=0.99, alpha=0.0005, gae_lambda=0.95,</div>
<div class="line"><a id="l00195" name="l00195"></a><span class="lineno">  195</span>                 policy_clip=0.2, batch_size=128, N=1024, n_epochs=5, model_name =&#39;ppo&#39;):</div>
<div class="line"><a id="l00196" name="l00196"></a><span class="lineno">  196</span>        <span class="stringliteral">&quot;&quot;&quot;!</span></div>
<div class="line"><a id="l00197" name="l00197"></a><span class="lineno">  197</span><span class="stringliteral">        @brief Initialize the PPO agent</span></div>
<div class="line"><a id="l00198" name="l00198"></a><span class="lineno">  198</span><span class="stringliteral">        @param input_dims Dimension of the state space</span></div>
<div class="line"><a id="l00199" name="l00199"></a><span class="lineno">  199</span><span class="stringliteral">        @param n_actions Number of possible actions</span></div>
<div class="line"><a id="l00200" name="l00200"></a><span class="lineno">  200</span><span class="stringliteral">        @param gamma Discount factor for future rewards</span></div>
<div class="line"><a id="l00201" name="l00201"></a><span class="lineno">  201</span><span class="stringliteral">        @param alpha Learning rate for both actor and critic networks</span></div>
<div class="line"><a id="l00202" name="l00202"></a><span class="lineno">  202</span><span class="stringliteral">        @param gae_lambda Lambda parameter for Generalized Advantage Estimation</span></div>
<div class="line"><a id="l00203" name="l00203"></a><span class="lineno">  203</span><span class="stringliteral">        @param policy_clip Clipping parameter for PPO objective</span></div>
<div class="line"><a id="l00204" name="l00204"></a><span class="lineno">  204</span><span class="stringliteral">        @param batch_size Size of training batches</span></div>
<div class="line"><a id="l00205" name="l00205"></a><span class="lineno">  205</span><span class="stringliteral">        @param N Number of steps to collect before learning</span></div>
<div class="line"><a id="l00206" name="l00206"></a><span class="lineno">  206</span><span class="stringliteral">        @param n_epochs Number of training epochs per learning step</span></div>
<div class="line"><a id="l00207" name="l00207"></a><span class="lineno">  207</span><span class="stringliteral">        @param model_name Name for saving/loading model checkpoints</span></div>
<div class="line"><a id="l00208" name="l00208"></a><span class="lineno">  208</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><a id="l00209" name="l00209"></a><span class="lineno"><a class="line" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent.html#a9a01dc3182b551836c5549a8c172b651">  209</a></span>        self.<a class="code hl_variable" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent.html#a9a01dc3182b551836c5549a8c172b651">gamma</a> = gamma</div>
<div class="line"><a id="l00210" name="l00210"></a><span class="lineno"><a class="line" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent.html#a6943862574b28a3371d19ee56455a544">  210</a></span>        self.<a class="code hl_variable" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent.html#a6943862574b28a3371d19ee56455a544">policy_clip</a> = policy_clip</div>
<div class="line"><a id="l00211" name="l00211"></a><span class="lineno"><a class="line" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent.html#a7ba79036643adb93f11d205be1dd0b5f">  211</a></span>        self.<a class="code hl_variable" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent.html#a7ba79036643adb93f11d205be1dd0b5f">n_epochs</a> = n_epochs</div>
<div class="line"><a id="l00212" name="l00212"></a><span class="lineno"><a class="line" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent.html#a2e14dfc5da07b12391625092aad3a8da">  212</a></span>        self.<a class="code hl_variable" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent.html#a2e14dfc5da07b12391625092aad3a8da">gae_lambda</a> = gae_lambda</div>
<div class="line"><a id="l00213" name="l00213"></a><span class="lineno">  213</span> </div>
<div class="line"><a id="l00214" name="l00214"></a><span class="lineno"><a class="line" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent.html#a30d5505efa99710341c579de4f3c7c03">  214</a></span>        self.<a class="code hl_variable" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent.html#a30d5505efa99710341c579de4f3c7c03">actor</a> = <a class="code hl_class" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_actor_network.html">ActorNetwork</a>(n_actions, input_dims, alpha, name = model_name)</div>
<div class="line"><a id="l00215" name="l00215"></a><span class="lineno"><a class="line" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent.html#a476d79433aee6877dcf08d4985a8b798">  215</a></span>        self.<a class="code hl_variable" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent.html#a476d79433aee6877dcf08d4985a8b798">critic</a> = <a class="code hl_class" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_critic_network.html">CriticNetwork</a>(input_dims, alpha, name = model_name)</div>
<div class="line"><a id="l00216" name="l00216"></a><span class="lineno"><a class="line" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent.html#aa806d28253ea490fc8b519af229bec28">  216</a></span>        self.<a class="code hl_variable" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent.html#aa806d28253ea490fc8b519af229bec28">memory</a> = <a class="code hl_class" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_memory.html">PPOMemory</a>(batch_size)</div>
<div class="line"><a id="l00217" name="l00217"></a><span class="lineno">  217</span> </div>
</div>
<div class="foldopen" id="foldopen00218" data-start="" data-end="">
<div class="line"><a id="l00218" name="l00218"></a><span class="lineno"><a class="line" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent.html#a7caa3ca2d12d84e7eab133650fa115c4">  218</a></span>    <span class="keyword">def </span><a class="code hl_function" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent.html#a7caa3ca2d12d84e7eab133650fa115c4">remember</a>(self, state, action, probs, values, reward, done):</div>
<div class="line"><a id="l00219" name="l00219"></a><span class="lineno">  219</span>        <span class="stringliteral">&quot;&quot;&quot;!</span></div>
<div class="line"><a id="l00220" name="l00220"></a><span class="lineno">  220</span><span class="stringliteral">        @brief Store an experience in the agent&#39;s memory</span></div>
<div class="line"><a id="l00221" name="l00221"></a><span class="lineno">  221</span><span class="stringliteral">        @param state Current state observation</span></div>
<div class="line"><a id="l00222" name="l00222"></a><span class="lineno">  222</span><span class="stringliteral">        @param action Action taken</span></div>
<div class="line"><a id="l00223" name="l00223"></a><span class="lineno">  223</span><span class="stringliteral">        @param probs Log probability of the action</span></div>
<div class="line"><a id="l00224" name="l00224"></a><span class="lineno">  224</span><span class="stringliteral">        @param values Value estimate for the state</span></div>
<div class="line"><a id="l00225" name="l00225"></a><span class="lineno">  225</span><span class="stringliteral">        @param reward Reward received</span></div>
<div class="line"><a id="l00226" name="l00226"></a><span class="lineno">  226</span><span class="stringliteral">        @param done Whether the episode is finished</span></div>
<div class="line"><a id="l00227" name="l00227"></a><span class="lineno">  227</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><a id="l00228" name="l00228"></a><span class="lineno">  228</span>        self.<a class="code hl_variable" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent.html#aa806d28253ea490fc8b519af229bec28">memory</a>.store_memory(state, action, probs, values, reward, done)</div>
<div class="line"><a id="l00229" name="l00229"></a><span class="lineno">  229</span> </div>
</div>
<div class="foldopen" id="foldopen00230" data-start="" data-end="">
<div class="line"><a id="l00230" name="l00230"></a><span class="lineno"><a class="line" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent.html#a470678495edd7cd31b9c58d6d95ed7c0">  230</a></span>    <span class="keyword">def </span><a class="code hl_function" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent.html#a470678495edd7cd31b9c58d6d95ed7c0">save_models</a>(self):</div>
<div class="line"><a id="l00231" name="l00231"></a><span class="lineno">  231</span>        <span class="stringliteral">&quot;&quot;&quot;!</span></div>
<div class="line"><a id="l00232" name="l00232"></a><span class="lineno">  232</span><span class="stringliteral">        @brief Save both actor and critic model checkpoints</span></div>
<div class="line"><a id="l00233" name="l00233"></a><span class="lineno">  233</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><a id="l00234" name="l00234"></a><span class="lineno">  234</span>        print(<span class="stringliteral">&#39;... saving models ...&#39;</span>)</div>
<div class="line"><a id="l00235" name="l00235"></a><span class="lineno">  235</span>        self.<a class="code hl_variable" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent.html#a30d5505efa99710341c579de4f3c7c03">actor</a>.save_checkpoint()</div>
<div class="line"><a id="l00236" name="l00236"></a><span class="lineno">  236</span>        self.<a class="code hl_variable" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent.html#a476d79433aee6877dcf08d4985a8b798">critic</a>.save_checkpoint()</div>
<div class="line"><a id="l00237" name="l00237"></a><span class="lineno">  237</span> </div>
</div>
<div class="foldopen" id="foldopen00238" data-start="" data-end="">
<div class="line"><a id="l00238" name="l00238"></a><span class="lineno"><a class="line" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent.html#a661abfa90d86386f305e8f947f0322f9">  238</a></span>    <span class="keyword">def </span><a class="code hl_function" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent.html#a661abfa90d86386f305e8f947f0322f9">load_models</a>(self):</div>
<div class="line"><a id="l00239" name="l00239"></a><span class="lineno">  239</span>        <span class="stringliteral">&quot;&quot;&quot;!</span></div>
<div class="line"><a id="l00240" name="l00240"></a><span class="lineno">  240</span><span class="stringliteral">        @brief Load both actor and critic model checkpoints</span></div>
<div class="line"><a id="l00241" name="l00241"></a><span class="lineno">  241</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><a id="l00242" name="l00242"></a><span class="lineno">  242</span>        print(<span class="stringliteral">&#39;... loading models ...&#39;</span>)</div>
<div class="line"><a id="l00243" name="l00243"></a><span class="lineno">  243</span>        self.<a class="code hl_variable" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent.html#a30d5505efa99710341c579de4f3c7c03">actor</a>.load_checkpoint()</div>
<div class="line"><a id="l00244" name="l00244"></a><span class="lineno">  244</span>        self.<a class="code hl_variable" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent.html#a476d79433aee6877dcf08d4985a8b798">critic</a>.load_checkpoint()</div>
<div class="line"><a id="l00245" name="l00245"></a><span class="lineno">  245</span> </div>
</div>
<div class="foldopen" id="foldopen00246" data-start="" data-end="">
<div class="line"><a id="l00246" name="l00246"></a><span class="lineno"><a class="line" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent.html#a8992b4ff91e79bc53277932481061250">  246</a></span>    <span class="keyword">def </span><a class="code hl_function" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent.html#a8992b4ff91e79bc53277932481061250">choose_action</a>(self, observation):</div>
<div class="line"><a id="l00247" name="l00247"></a><span class="lineno">  247</span>        <span class="stringliteral">&quot;&quot;&quot;!</span></div>
<div class="line"><a id="l00248" name="l00248"></a><span class="lineno">  248</span><span class="stringliteral">        @brief Choose an action based on the current observation</span></div>
<div class="line"><a id="l00249" name="l00249"></a><span class="lineno">  249</span><span class="stringliteral">        @param observation Current state observation</span></div>
<div class="line"><a id="l00250" name="l00250"></a><span class="lineno">  250</span><span class="stringliteral">        @return Tuple of (action, log_probability, value_estimate, action_distribution)</span></div>
<div class="line"><a id="l00251" name="l00251"></a><span class="lineno">  251</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><a id="l00252" name="l00252"></a><span class="lineno">  252</span>        <span class="comment"># Convert observation to tensor</span></div>
<div class="line"><a id="l00253" name="l00253"></a><span class="lineno">  253</span>        state = T.tensor(observation, dtype=T.float).to(self.<a class="code hl_variable" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent.html#a30d5505efa99710341c579de4f3c7c03">actor</a>.device)</div>
<div class="line"><a id="l00254" name="l00254"></a><span class="lineno">  254</span> </div>
<div class="line"><a id="l00255" name="l00255"></a><span class="lineno">  255</span>        dist = self.<a class="code hl_variable" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent.html#a30d5505efa99710341c579de4f3c7c03">actor</a>(state)</div>
<div class="line"><a id="l00256" name="l00256"></a><span class="lineno">  256</span>        value = self.<a class="code hl_variable" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent.html#a476d79433aee6877dcf08d4985a8b798">critic</a>(state)</div>
<div class="line"><a id="l00257" name="l00257"></a><span class="lineno">  257</span>        action = dist.sample()</div>
<div class="line"><a id="l00258" name="l00258"></a><span class="lineno">  258</span> </div>
<div class="line"><a id="l00259" name="l00259"></a><span class="lineno">  259</span>        probs = T.squeeze(dist.log_prob(action)).item()</div>
<div class="line"><a id="l00260" name="l00260"></a><span class="lineno">  260</span>        action = T.squeeze(action).item()</div>
<div class="line"><a id="l00261" name="l00261"></a><span class="lineno">  261</span>        value = T.squeeze(value).item()</div>
<div class="line"><a id="l00262" name="l00262"></a><span class="lineno">  262</span> </div>
<div class="line"><a id="l00263" name="l00263"></a><span class="lineno">  263</span>        <span class="keywordflow">return</span> action, probs, value, dist</div>
<div class="line"><a id="l00264" name="l00264"></a><span class="lineno">  264</span> </div>
<div class="line"><a id="l00265" name="l00265"></a><span class="lineno">  265</span> </div>
</div>
<div class="foldopen" id="foldopen00266" data-start="" data-end="">
<div class="line"><a id="l00266" name="l00266"></a><span class="lineno"><a class="line" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent.html#a7899457347773c0e1ef284fe4cd91d19">  266</a></span>    <span class="keyword">def </span><a class="code hl_function" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent.html#a7899457347773c0e1ef284fe4cd91d19">learn</a>(self):</div>
<div class="line"><a id="l00267" name="l00267"></a><span class="lineno">  267</span>        <span class="stringliteral">&quot;&quot;&quot;!</span></div>
<div class="line"><a id="l00268" name="l00268"></a><span class="lineno">  268</span><span class="stringliteral">        @brief Perform PPO learning update using stored experiences</span></div>
<div class="line"><a id="l00269" name="l00269"></a><span class="lineno">  269</span><span class="stringliteral">        </span></div>
<div class="line"><a id="l00270" name="l00270"></a><span class="lineno">  270</span><span class="stringliteral">        Implements the PPO algorithm with clipped probability ratios and </span></div>
<div class="line"><a id="l00271" name="l00271"></a><span class="lineno">  271</span><span class="stringliteral">        Generalized Advantage Estimation (GAE). Updates both actor and </span></div>
<div class="line"><a id="l00272" name="l00272"></a><span class="lineno">  272</span><span class="stringliteral">        critic networks for multiple epochs.</span></div>
<div class="line"><a id="l00273" name="l00273"></a><span class="lineno">  273</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><a id="l00274" name="l00274"></a><span class="lineno">  274</span>        <span class="keywordflow">for</span> _ <span class="keywordflow">in</span> range(self.<a class="code hl_variable" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent.html#a7ba79036643adb93f11d205be1dd0b5f">n_epochs</a>):</div>
<div class="line"><a id="l00275" name="l00275"></a><span class="lineno">  275</span>            state_arr, action_arr, old_probs_arr, values_arr,\</div>
<div class="line"><a id="l00276" name="l00276"></a><span class="lineno">  276</span>            reward_arr, done_arr, batches = self.<a class="code hl_variable" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent.html#aa806d28253ea490fc8b519af229bec28">memory</a>.generate_batches()</div>
<div class="line"><a id="l00277" name="l00277"></a><span class="lineno">  277</span> </div>
<div class="line"><a id="l00278" name="l00278"></a><span class="lineno">  278</span>            values = values_arr</div>
<div class="line"><a id="l00279" name="l00279"></a><span class="lineno">  279</span>            advantages = np.zeros(len(reward_arr), dtype=np.float32)</div>
<div class="line"><a id="l00280" name="l00280"></a><span class="lineno">  280</span> </div>
<div class="line"><a id="l00281" name="l00281"></a><span class="lineno">  281</span>            <span class="comment"># Calculate advantages using GAE</span></div>
<div class="line"><a id="l00282" name="l00282"></a><span class="lineno">  282</span>            <span class="keywordflow">for</span> t <span class="keywordflow">in</span> range(len(reward_arr)-1):</div>
<div class="line"><a id="l00283" name="l00283"></a><span class="lineno">  283</span>                discount = 1</div>
<div class="line"><a id="l00284" name="l00284"></a><span class="lineno">  284</span>                a_t = 0</div>
<div class="line"><a id="l00285" name="l00285"></a><span class="lineno">  285</span>                <span class="keywordflow">for</span> k <span class="keywordflow">in</span> range(t, len(reward_arr)-1):</div>
<div class="line"><a id="l00286" name="l00286"></a><span class="lineno">  286</span>                   a_t += discount*(reward_arr[k] + self.<a class="code hl_variable" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent.html#a9a01dc3182b551836c5549a8c172b651">gamma</a>*values[k+1]*(1-int(done_arr[k])) - values[k])</div>
<div class="line"><a id="l00287" name="l00287"></a><span class="lineno">  287</span>                   discount *= self.<a class="code hl_variable" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent.html#a9a01dc3182b551836c5549a8c172b651">gamma</a>*self.<a class="code hl_variable" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent.html#a2e14dfc5da07b12391625092aad3a8da">gae_lambda</a></div>
<div class="line"><a id="l00288" name="l00288"></a><span class="lineno">  288</span>                advantages[t] = a_t</div>
<div class="line"><a id="l00289" name="l00289"></a><span class="lineno">  289</span> </div>
<div class="line"><a id="l00290" name="l00290"></a><span class="lineno">  290</span>            advantage = T.tensor(advantages).to(self.<a class="code hl_variable" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent.html#a30d5505efa99710341c579de4f3c7c03">actor</a>.device)</div>
<div class="line"><a id="l00291" name="l00291"></a><span class="lineno">  291</span>            values = T.tensor(values).to(self.<a class="code hl_variable" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent.html#a30d5505efa99710341c579de4f3c7c03">actor</a>.device)</div>
<div class="line"><a id="l00292" name="l00292"></a><span class="lineno">  292</span> </div>
<div class="line"><a id="l00293" name="l00293"></a><span class="lineno">  293</span>            <span class="comment"># Train on each batch</span></div>
<div class="line"><a id="l00294" name="l00294"></a><span class="lineno">  294</span>            <span class="keywordflow">for</span> batch <span class="keywordflow">in</span> batches:</div>
<div class="line"><a id="l00295" name="l00295"></a><span class="lineno">  295</span>                states = T.tensor(state_arr[batch], dtype=T.float).to(self.<a class="code hl_variable" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent.html#a30d5505efa99710341c579de4f3c7c03">actor</a>.device)</div>
<div class="line"><a id="l00296" name="l00296"></a><span class="lineno">  296</span>                old_probs = T.tensor(old_probs_arr[batch]).to(self.<a class="code hl_variable" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent.html#a30d5505efa99710341c579de4f3c7c03">actor</a>.device)</div>
<div class="line"><a id="l00297" name="l00297"></a><span class="lineno">  297</span>                actions = T.tensor(action_arr[batch]).to(self.<a class="code hl_variable" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent.html#a30d5505efa99710341c579de4f3c7c03">actor</a>.device)</div>
<div class="line"><a id="l00298" name="l00298"></a><span class="lineno">  298</span> </div>
<div class="line"><a id="l00299" name="l00299"></a><span class="lineno">  299</span>                dist = self.<a class="code hl_variable" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent.html#a30d5505efa99710341c579de4f3c7c03">actor</a>(states)</div>
<div class="line"><a id="l00300" name="l00300"></a><span class="lineno">  300</span>                critic_value = self.<a class="code hl_variable" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent.html#a476d79433aee6877dcf08d4985a8b798">critic</a>(states)</div>
<div class="line"><a id="l00301" name="l00301"></a><span class="lineno">  301</span> </div>
<div class="line"><a id="l00302" name="l00302"></a><span class="lineno">  302</span>                critic_value = T.squeeze(critic_value)</div>
<div class="line"><a id="l00303" name="l00303"></a><span class="lineno">  303</span> </div>
<div class="line"><a id="l00304" name="l00304"></a><span class="lineno">  304</span>                <span class="comment"># Calculate probability ratio and apply clipping</span></div>
<div class="line"><a id="l00305" name="l00305"></a><span class="lineno">  305</span>                new_probs = dist.log_prob(actions)</div>
<div class="line"><a id="l00306" name="l00306"></a><span class="lineno">  306</span>                prob_ratio = new_probs.exp() / old_probs.exp()</div>
<div class="line"><a id="l00307" name="l00307"></a><span class="lineno">  307</span>                weighted_probs = advantage[batch] * prob_ratio</div>
<div class="line"><a id="l00308" name="l00308"></a><span class="lineno">  308</span>                weighted_clipped_probs = T.clamp(prob_ratio, 1-self.<a class="code hl_variable" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent.html#a6943862574b28a3371d19ee56455a544">policy_clip</a>, 1+self.<a class="code hl_variable" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent.html#a6943862574b28a3371d19ee56455a544">policy_clip</a>) * advantage[batch]</div>
<div class="line"><a id="l00309" name="l00309"></a><span class="lineno">  309</span>                actor_loss = -T.min(weighted_probs, weighted_clipped_probs).mean()</div>
<div class="line"><a id="l00310" name="l00310"></a><span class="lineno">  310</span> </div>
<div class="line"><a id="l00311" name="l00311"></a><span class="lineno">  311</span>                <span class="comment"># Calculate critic loss</span></div>
<div class="line"><a id="l00312" name="l00312"></a><span class="lineno">  312</span>                returns = advantage[batch] + values[batch]</div>
<div class="line"><a id="l00313" name="l00313"></a><span class="lineno">  313</span>                critic_loss = (returns-critic_value)**2</div>
<div class="line"><a id="l00314" name="l00314"></a><span class="lineno">  314</span>                critic_loss = critic_loss.mean()</div>
<div class="line"><a id="l00315" name="l00315"></a><span class="lineno">  315</span> </div>
<div class="line"><a id="l00316" name="l00316"></a><span class="lineno">  316</span>                <span class="comment"># Combined loss and backpropagation</span></div>
<div class="line"><a id="l00317" name="l00317"></a><span class="lineno">  317</span>                total_loss = actor_loss + 0.5*critic_loss</div>
<div class="line"><a id="l00318" name="l00318"></a><span class="lineno">  318</span>                self.<a class="code hl_variable" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent.html#a30d5505efa99710341c579de4f3c7c03">actor</a>.optimizer.zero_grad()</div>
<div class="line"><a id="l00319" name="l00319"></a><span class="lineno">  319</span>                self.<a class="code hl_variable" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent.html#a476d79433aee6877dcf08d4985a8b798">critic</a>.optimizer.zero_grad()</div>
<div class="line"><a id="l00320" name="l00320"></a><span class="lineno">  320</span>                total_loss.backward()</div>
<div class="line"><a id="l00321" name="l00321"></a><span class="lineno">  321</span>                self.<a class="code hl_variable" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent.html#a30d5505efa99710341c579de4f3c7c03">actor</a>.optimizer.step()</div>
<div class="line"><a id="l00322" name="l00322"></a><span class="lineno">  322</span>                self.<a class="code hl_variable" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent.html#a476d79433aee6877dcf08d4985a8b798">critic</a>.optimizer.step()</div>
<div class="line"><a id="l00323" name="l00323"></a><span class="lineno">  323</span> </div>
<div class="line"><a id="l00324" name="l00324"></a><span class="lineno">  324</span>        self.<a class="code hl_variable" href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent.html#aa806d28253ea490fc8b519af229bec28">memory</a>.clear_memory()</div>
<div class="line"><a id="l00325" name="l00325"></a><span class="lineno">  325</span> </div>
</div>
</div>
<div class="ttc" id="aclassrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_actor_network_html"><div class="ttname"><a href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_actor_network.html">rl.agents.high_level.ppo_agent.ActorNetwork</a></div><div class="ttdoc">Actor network for PPO agent.</div><div class="ttdef"><b>Definition</b> <a href="#l00075">ppo_agent.py:75</a></div></div>
<div class="ttc" id="aclassrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_actor_network_html_a0f4ea4666192124613d9c1073cd5951c"><div class="ttname"><a href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_actor_network.html#a0f4ea4666192124613d9c1073cd5951c">rl.agents.high_level.ppo_agent.ActorNetwork.load_checkpoint</a></div><div class="ttdeci">load_checkpoint(self)</div><div class="ttdoc">Load model state from checkpoint file.</div><div class="ttdef"><b>Definition</b> <a href="#l00124">ppo_agent.py:124</a></div></div>
<div class="ttc" id="aclassrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_actor_network_html_a1a3c826967f0c48bd422494b0a61aa35"><div class="ttname"><a href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_actor_network.html#a1a3c826967f0c48bd422494b0a61aa35">rl.agents.high_level.ppo_agent.ActorNetwork.device</a></div><div class="ttdeci">device</div><div class="ttdef"><b>Definition</b> <a href="#l00104">ppo_agent.py:104</a></div></div>
<div class="ttc" id="aclassrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_actor_network_html_a205adbf70f3a9fa366ab0fcdee380333"><div class="ttname"><a href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_actor_network.html#a205adbf70f3a9fa366ab0fcdee380333">rl.agents.high_level.ppo_agent.ActorNetwork.forward</a></div><div class="ttdeci">forward(self, state)</div><div class="ttdoc">Forward pass through the actor network.</div><div class="ttdef"><b>Definition</b> <a href="#l00107">ppo_agent.py:107</a></div></div>
<div class="ttc" id="aclassrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_actor_network_html_a28ce44f0321d73d4cbcef057607fcf16"><div class="ttname"><a href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_actor_network.html#a28ce44f0321d73d4cbcef057607fcf16">rl.agents.high_level.ppo_agent.ActorNetwork.actor</a></div><div class="ttdeci">actor</div><div class="ttdef"><b>Definition</b> <a href="#l00098">ppo_agent.py:98</a></div></div>
<div class="ttc" id="aclassrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_actor_network_html_a67e4554ca3dd016844a0073df5ff6cbf"><div class="ttname"><a href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_actor_network.html#a67e4554ca3dd016844a0073df5ff6cbf">rl.agents.high_level.ppo_agent.ActorNetwork.checkpoint_file</a></div><div class="ttdeci">checkpoint_file</div><div class="ttdef"><b>Definition</b> <a href="#l00097">ppo_agent.py:97</a></div></div>
<div class="ttc" id="aclassrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_actor_network_html_a8bc09dc4a05f9d935d74e45d2d7e459c"><div class="ttname"><a href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_actor_network.html#a8bc09dc4a05f9d935d74e45d2d7e459c">rl.agents.high_level.ppo_agent.ActorNetwork.save_checkpoint</a></div><div class="ttdeci">save_checkpoint(self)</div><div class="ttdoc">Save the current model state to checkpoint file.</div><div class="ttdef"><b>Definition</b> <a href="#l00118">ppo_agent.py:118</a></div></div>
<div class="ttc" id="aclassrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_actor_network_html_a94510c3daa25640bed11a76900a888a5"><div class="ttname"><a href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_actor_network.html#a94510c3daa25640bed11a76900a888a5">rl.agents.high_level.ppo_agent.ActorNetwork.optimizer</a></div><div class="ttdeci">optimizer</div><div class="ttdef"><b>Definition</b> <a href="#l00103">ppo_agent.py:103</a></div></div>
<div class="ttc" id="aclassrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_actor_network_html_aee7d89c100fcc1aee1870322de45a72d"><div class="ttname"><a href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_actor_network.html#aee7d89c100fcc1aee1870322de45a72d">rl.agents.high_level.ppo_agent.ActorNetwork.__init__</a></div><div class="ttdeci">__init__(self, n_actions, input_dims, alpha, fc1dims=256, fc2dims=256, fc3dims=128, chkpt_dir='tmp/ppo', name='ppo')</div><div class="ttdoc">Initialize the actor network.</div><div class="ttdef"><b>Definition</b> <a href="#l00083">ppo_agent.py:83</a></div></div>
<div class="ttc" id="aclassrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_critic_network_html"><div class="ttname"><a href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_critic_network.html">rl.agents.high_level.ppo_agent.CriticNetwork</a></div><div class="ttdoc">Critic network for PPO agent.</div><div class="ttdef"><b>Definition</b> <a href="#l00131">ppo_agent.py:131</a></div></div>
<div class="ttc" id="aclassrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_critic_network_html_a0f8199be7d8c7e801ff0b88336b96213"><div class="ttname"><a href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_critic_network.html#a0f8199be7d8c7e801ff0b88336b96213">rl.agents.high_level.ppo_agent.CriticNetwork.checkpoint_file</a></div><div class="ttdeci">checkpoint_file</div><div class="ttdef"><b>Definition</b> <a href="#l00152">ppo_agent.py:152</a></div></div>
<div class="ttc" id="aclassrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_critic_network_html_a56a2a9b7dd1e46f6cca7cd7f3b18e649"><div class="ttname"><a href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_critic_network.html#a56a2a9b7dd1e46f6cca7cd7f3b18e649">rl.agents.high_level.ppo_agent.CriticNetwork.save_checkpoint</a></div><div class="ttdeci">save_checkpoint(self)</div><div class="ttdoc">Save the current model state to checkpoint file.</div><div class="ttdef"><b>Definition</b> <a href="#l00172">ppo_agent.py:172</a></div></div>
<div class="ttc" id="aclassrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_critic_network_html_a824b1eed500fc53536c0f7e01d176988"><div class="ttname"><a href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_critic_network.html#a824b1eed500fc53536c0f7e01d176988">rl.agents.high_level.ppo_agent.CriticNetwork.critic</a></div><div class="ttdeci">critic</div><div class="ttdef"><b>Definition</b> <a href="#l00153">ppo_agent.py:153</a></div></div>
<div class="ttc" id="aclassrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_critic_network_html_a83eec626281fcdfb93996bb50aee40a8"><div class="ttname"><a href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_critic_network.html#a83eec626281fcdfb93996bb50aee40a8">rl.agents.high_level.ppo_agent.CriticNetwork.device</a></div><div class="ttdeci">device</div><div class="ttdef"><b>Definition</b> <a href="#l00159">ppo_agent.py:159</a></div></div>
<div class="ttc" id="aclassrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_critic_network_html_acd6e3b7f5abc211d93a99509914e248a"><div class="ttname"><a href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_critic_network.html#acd6e3b7f5abc211d93a99509914e248a">rl.agents.high_level.ppo_agent.CriticNetwork.load_checkpoint</a></div><div class="ttdeci">load_checkpoint(self)</div><div class="ttdoc">Load model state from checkpoint file.</div><div class="ttdef"><b>Definition</b> <a href="#l00178">ppo_agent.py:178</a></div></div>
<div class="ttc" id="aclassrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_critic_network_html_ad2c14eed568cf52935eda79be9e6916f"><div class="ttname"><a href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_critic_network.html#ad2c14eed568cf52935eda79be9e6916f">rl.agents.high_level.ppo_agent.CriticNetwork.optimizer</a></div><div class="ttdeci">optimizer</div><div class="ttdef"><b>Definition</b> <a href="#l00158">ppo_agent.py:158</a></div></div>
<div class="ttc" id="aclassrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_critic_network_html_ae3f0e45a7ac28221a69ed2d0a91d5283"><div class="ttname"><a href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_critic_network.html#ae3f0e45a7ac28221a69ed2d0a91d5283">rl.agents.high_level.ppo_agent.CriticNetwork.__init__</a></div><div class="ttdeci">__init__(self, input_dims, alpha, fc1dims=256, fc2dims=256, fc3dims=128, chkpt_dir='tmp/ppo', name='ppo')</div><div class="ttdoc">Initialize the critic network.</div><div class="ttdef"><b>Definition</b> <a href="#l00139">ppo_agent.py:139</a></div></div>
<div class="ttc" id="aclassrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_critic_network_html_ae4e70fa5ae609b2ea791905c0c7c37bc"><div class="ttname"><a href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_critic_network.html#ae4e70fa5ae609b2ea791905c0c7c37bc">rl.agents.high_level.ppo_agent.CriticNetwork.forward</a></div><div class="ttdeci">forward(self, state)</div><div class="ttdoc">Forward pass through the critic network.</div><div class="ttdef"><b>Definition</b> <a href="#l00162">ppo_agent.py:162</a></div></div>
<div class="ttc" id="aclassrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent_html"><div class="ttname"><a href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent.html">rl.agents.high_level.ppo_agent.PPOAgent</a></div><div class="ttdoc">Proximal Policy Optimization (PPO) agent implementation.</div><div class="ttdef"><b>Definition</b> <a href="#l00185">ppo_agent.py:185</a></div></div>
<div class="ttc" id="aclassrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent_html_a2a0c96183d523d54d8203e10dcb129a3"><div class="ttname"><a href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent.html#a2a0c96183d523d54d8203e10dcb129a3">rl.agents.high_level.ppo_agent.PPOAgent.__init__</a></div><div class="ttdeci">__init__(self, input_dims, n_actions, gamma=0.99, alpha=0.0005, gae_lambda=0.95, policy_clip=0.2, batch_size=128, N=1024, n_epochs=5, model_name='ppo')</div><div class="ttdoc">Initialize the PPO agent.</div><div class="ttdef"><b>Definition</b> <a href="#l00194">ppo_agent.py:195</a></div></div>
<div class="ttc" id="aclassrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent_html_a2e14dfc5da07b12391625092aad3a8da"><div class="ttname"><a href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent.html#a2e14dfc5da07b12391625092aad3a8da">rl.agents.high_level.ppo_agent.PPOAgent.gae_lambda</a></div><div class="ttdeci">gae_lambda</div><div class="ttdef"><b>Definition</b> <a href="#l00212">ppo_agent.py:212</a></div></div>
<div class="ttc" id="aclassrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent_html_a30d5505efa99710341c579de4f3c7c03"><div class="ttname"><a href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent.html#a30d5505efa99710341c579de4f3c7c03">rl.agents.high_level.ppo_agent.PPOAgent.actor</a></div><div class="ttdeci">actor</div><div class="ttdef"><b>Definition</b> <a href="#l00214">ppo_agent.py:214</a></div></div>
<div class="ttc" id="aclassrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent_html_a470678495edd7cd31b9c58d6d95ed7c0"><div class="ttname"><a href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent.html#a470678495edd7cd31b9c58d6d95ed7c0">rl.agents.high_level.ppo_agent.PPOAgent.save_models</a></div><div class="ttdeci">save_models(self)</div><div class="ttdoc">Save both actor and critic model checkpoints.</div><div class="ttdef"><b>Definition</b> <a href="#l00230">ppo_agent.py:230</a></div></div>
<div class="ttc" id="aclassrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent_html_a476d79433aee6877dcf08d4985a8b798"><div class="ttname"><a href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent.html#a476d79433aee6877dcf08d4985a8b798">rl.agents.high_level.ppo_agent.PPOAgent.critic</a></div><div class="ttdeci">critic</div><div class="ttdef"><b>Definition</b> <a href="#l00215">ppo_agent.py:215</a></div></div>
<div class="ttc" id="aclassrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent_html_a661abfa90d86386f305e8f947f0322f9"><div class="ttname"><a href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent.html#a661abfa90d86386f305e8f947f0322f9">rl.agents.high_level.ppo_agent.PPOAgent.load_models</a></div><div class="ttdeci">load_models(self)</div><div class="ttdoc">Load both actor and critic model checkpoints.</div><div class="ttdef"><b>Definition</b> <a href="#l00238">ppo_agent.py:238</a></div></div>
<div class="ttc" id="aclassrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent_html_a6943862574b28a3371d19ee56455a544"><div class="ttname"><a href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent.html#a6943862574b28a3371d19ee56455a544">rl.agents.high_level.ppo_agent.PPOAgent.policy_clip</a></div><div class="ttdeci">policy_clip</div><div class="ttdef"><b>Definition</b> <a href="#l00210">ppo_agent.py:210</a></div></div>
<div class="ttc" id="aclassrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent_html_a7899457347773c0e1ef284fe4cd91d19"><div class="ttname"><a href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent.html#a7899457347773c0e1ef284fe4cd91d19">rl.agents.high_level.ppo_agent.PPOAgent.learn</a></div><div class="ttdeci">learn(self)</div><div class="ttdoc">Perform PPO learning update using stored experiences.</div><div class="ttdef"><b>Definition</b> <a href="#l00266">ppo_agent.py:266</a></div></div>
<div class="ttc" id="aclassrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent_html_a7ba79036643adb93f11d205be1dd0b5f"><div class="ttname"><a href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent.html#a7ba79036643adb93f11d205be1dd0b5f">rl.agents.high_level.ppo_agent.PPOAgent.n_epochs</a></div><div class="ttdeci">n_epochs</div><div class="ttdef"><b>Definition</b> <a href="#l00211">ppo_agent.py:211</a></div></div>
<div class="ttc" id="aclassrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent_html_a7caa3ca2d12d84e7eab133650fa115c4"><div class="ttname"><a href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent.html#a7caa3ca2d12d84e7eab133650fa115c4">rl.agents.high_level.ppo_agent.PPOAgent.remember</a></div><div class="ttdeci">remember(self, state, action, probs, values, reward, done)</div><div class="ttdoc">Store an experience in the agent's memory.</div><div class="ttdef"><b>Definition</b> <a href="#l00218">ppo_agent.py:218</a></div></div>
<div class="ttc" id="aclassrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent_html_a8992b4ff91e79bc53277932481061250"><div class="ttname"><a href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent.html#a8992b4ff91e79bc53277932481061250">rl.agents.high_level.ppo_agent.PPOAgent.choose_action</a></div><div class="ttdeci">choose_action(self, observation)</div><div class="ttdoc">Choose an action based on the current observation.</div><div class="ttdef"><b>Definition</b> <a href="#l00246">ppo_agent.py:246</a></div></div>
<div class="ttc" id="aclassrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent_html_a9a01dc3182b551836c5549a8c172b651"><div class="ttname"><a href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent.html#a9a01dc3182b551836c5549a8c172b651">rl.agents.high_level.ppo_agent.PPOAgent.gamma</a></div><div class="ttdeci">gamma</div><div class="ttdef"><b>Definition</b> <a href="#l00209">ppo_agent.py:209</a></div></div>
<div class="ttc" id="aclassrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent_html_aa806d28253ea490fc8b519af229bec28"><div class="ttname"><a href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_agent.html#aa806d28253ea490fc8b519af229bec28">rl.agents.high_level.ppo_agent.PPOAgent.memory</a></div><div class="ttdeci">memory</div><div class="ttdef"><b>Definition</b> <a href="#l00216">ppo_agent.py:216</a></div></div>
<div class="ttc" id="aclassrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_memory_html"><div class="ttname"><a href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_memory.html">rl.agents.high_level.ppo_agent.PPOMemory</a></div><div class="ttdoc">Memory buffer for storing PPO training experiences.</div><div class="ttdef"><b>Definition</b> <a href="#l00008">ppo_agent.py:8</a></div></div>
<div class="ttc" id="aclassrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_memory_html_a0add6132e8c45fde1017f3d1b9fd62e1"><div class="ttname"><a href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_memory.html#a0add6132e8c45fde1017f3d1b9fd62e1">rl.agents.high_level.ppo_agent.PPOMemory.states</a></div><div class="ttdeci">list states</div><div class="ttdef"><b>Definition</b> <a href="#l00021">ppo_agent.py:21</a></div></div>
<div class="ttc" id="aclassrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_memory_html_a0b27fdd1b6d3d971bc034b616b58f7d7"><div class="ttname"><a href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_memory.html#a0b27fdd1b6d3d971bc034b616b58f7d7">rl.agents.high_level.ppo_agent.PPOMemory.clear_memory</a></div><div class="ttdeci">clear_memory(self)</div><div class="ttdoc">Clear all stored experiences from memory.</div><div class="ttdef"><b>Definition</b> <a href="#l00063">ppo_agent.py:63</a></div></div>
<div class="ttc" id="aclassrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_memory_html_a0c97a17d1a3dd1bcfbe8bc82655dee63"><div class="ttname"><a href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_memory.html#a0c97a17d1a3dd1bcfbe8bc82655dee63">rl.agents.high_level.ppo_agent.PPOMemory.batch_size</a></div><div class="ttdeci">batch_size</div><div class="ttdef"><b>Definition</b> <a href="#l00028">ppo_agent.py:28</a></div></div>
<div class="ttc" id="aclassrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_memory_html_a0e9efad74c28d7fd7e7bd0fda0257cac"><div class="ttname"><a href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_memory.html#a0e9efad74c28d7fd7e7bd0fda0257cac">rl.agents.high_level.ppo_agent.PPOMemory.dones</a></div><div class="ttdeci">list dones</div><div class="ttdef"><b>Definition</b> <a href="#l00026">ppo_agent.py:26</a></div></div>
<div class="ttc" id="aclassrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_memory_html_a3bf4561f4eb99d3693f9128ae0522b69"><div class="ttname"><a href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_memory.html#a3bf4561f4eb99d3693f9128ae0522b69">rl.agents.high_level.ppo_agent.PPOMemory.actions</a></div><div class="ttdeci">list actions</div><div class="ttdef"><b>Definition</b> <a href="#l00024">ppo_agent.py:24</a></div></div>
<div class="ttc" id="aclassrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_memory_html_a47453ce0abdb11c30dd9f8222a96b457"><div class="ttname"><a href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_memory.html#a47453ce0abdb11c30dd9f8222a96b457">rl.agents.high_level.ppo_agent.PPOMemory.values</a></div><div class="ttdeci">list values</div><div class="ttdef"><b>Definition</b> <a href="#l00023">ppo_agent.py:23</a></div></div>
<div class="ttc" id="aclassrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_memory_html_a4a87d310ee11c3ce1d58da34eb7b7d03"><div class="ttname"><a href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_memory.html#a4a87d310ee11c3ce1d58da34eb7b7d03">rl.agents.high_level.ppo_agent.PPOMemory.generate_batches</a></div><div class="ttdeci">generate_batches(self)</div><div class="ttdoc">Generate randomized training batches from stored experiences.</div><div class="ttdef"><b>Definition</b> <a href="#l00030">ppo_agent.py:30</a></div></div>
<div class="ttc" id="aclassrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_memory_html_a4be12d895d6566a136a7e7d3a437da6e"><div class="ttname"><a href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_memory.html#a4be12d895d6566a136a7e7d3a437da6e">rl.agents.high_level.ppo_agent.PPOMemory.__init__</a></div><div class="ttdeci">__init__(self, batch_size)</div><div class="ttdoc">Initialize the PPO memory buffer.</div><div class="ttdef"><b>Definition</b> <a href="#l00016">ppo_agent.py:16</a></div></div>
<div class="ttc" id="aclassrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_memory_html_aba4f59ce24a7a1e276c121cf9fff1512"><div class="ttname"><a href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_memory.html#aba4f59ce24a7a1e276c121cf9fff1512">rl.agents.high_level.ppo_agent.PPOMemory.probs</a></div><div class="ttdeci">list probs</div><div class="ttdef"><b>Definition</b> <a href="#l00022">ppo_agent.py:22</a></div></div>
<div class="ttc" id="aclassrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_memory_html_acb69a1ceca60755d44ff61f0b7eb4d93"><div class="ttname"><a href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_memory.html#acb69a1ceca60755d44ff61f0b7eb4d93">rl.agents.high_level.ppo_agent.PPOMemory.store_memory</a></div><div class="ttdeci">store_memory(self, state, action, probs, values, reward, done)</div><div class="ttdoc">Store a single experience in the memory buffer.</div><div class="ttdef"><b>Definition</b> <a href="#l00046">ppo_agent.py:46</a></div></div>
<div class="ttc" id="aclassrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_memory_html_acf933f33d5540126ed764ff35e0667ef"><div class="ttname"><a href="classrl_1_1agents_1_1high__level_1_1ppo__agent_1_1_p_p_o_memory.html#acf933f33d5540126ed764ff35e0667ef">rl.agents.high_level.ppo_agent.PPOMemory.rewards</a></div><div class="ttdeci">list rewards</div><div class="ttdef"><b>Definition</b> <a href="#l00025">ppo_agent.py:25</a></div></div>
</div><!-- fragment --></div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="dir_d1d5dfcd59b3eef155f3bc22ed21a40e.html">rl</a></li><li class="navelem"><a class="el" href="dir_dc6d1c16634ee458e0fe2cacd09b230e.html">agents</a></li><li class="navelem"><a class="el" href="dir_59c52f8927e8aa0154a183c7cb49af09.html">high_level</a></li><li class="navelem"><a class="el" href="ppo__agent_8py.html">ppo_agent.py</a></li>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.12.0 </li>
  </ul>
</div>
</body>
</html>
