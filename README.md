# ArchitekturÃ¼bersicht: Hierarchischer RL-Agent fÃ¼r die Beluga Challenge

Unsere Architektur basiert auf einem hierarchischen Entscheidungsansatz. Der High-Level-Agent trifft strategische Entscheidungen, wÃ¤hrend die Parametrisierung und AusfÃ¼hrung Ã¼ber spezialisierte Low-Level-Mechanismen erfolgt:
![agent-architecture](https://github.com/user-attachments/assets/ac2d5b83-8f99-4fbd-b97b-1441114ee30b)



## Komponenten

- **High-Level Agent**  
  WÃ¤hlt eine von acht mÃ¶glichen Aktionen aus (z.â€¯B. *Load Jig*, *Swap*, *Dispatch*). Trainiert mit Proximal Policy Optimization (PPO).

- **Low-Level Agent**  
  Verfeinert und fÃ¼hrt die vom High-Level-Agenten gewÃ¤hlte Aktion aus. AbhÃ¤ngig von der Aktionsart geschieht dies durch:
  - ğŸ”¹ *Direkte AusfÃ¼hrung* (z.â€¯B. deterministisch lÃ¶sbare Aktionen ohne Parameter)
  - ğŸ”¹ *Heuristiken* (fÃ¼r einfache, aber parametrisierte Aktionen)
  - ğŸ”¹ *Monte Carlo Tree Search (MCTS)* (fÃ¼r komplexe, sequenzielle Entscheidungen mit hohem Kombinationsraum)

Diese modulare Trennung erlaubt es, unterschiedliche AnsÃ¤tze (RL, Heuristiken, MCTS) synergetisch zu kombinieren und gezielt auf die Charakteristika einzelner Teilprobleme anzuwenden.
